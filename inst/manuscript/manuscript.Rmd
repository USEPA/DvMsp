---
title: A comparison of design-based and model-based approaches for finite population spatial data.
author:
  - name: Michael Dumelle
    affiliation: USEPA
    footnote: 1
  - name: Matt Higham
    affiliation: STLAW
  - name: Jay M. Ver Hoef
    affiliation: NOAA
  - name: Anthony R. Olsen
    affiliation: USEPA
  - name: Lisa Madsen
    affiliation: OSU
address:
  - code: USEPA
    address: United States Environmental Protection Agency, 200 SW 35th St, Corvallis, Oregon, 97333
  - code: STLAW
    address: Saint Lawrence University Department of Mathematics, Computer Science, and Statistics, 23 Romoda Drive, Canton, New York, 13617
  - code: NOAA
    address: Marine Mammal Laboratory, Alaska Fisheries Science Center, National Oceanic and Atmospheric Administration, Seattle, Washington, 98115
  - code: OSU
    address: Oregon State University Department of Statistics, 239 Weniger Hall, Corvallis, Oregon, 97331
footnote:
    code: 1
    text: "Corresponding Author: Michael Dumelle (Dumelle.Michael@epa.gov)"
abstract: |
  1.   The design-based and model-based approaches to frequentist statistical inference rest on fundamentally different foundations. In the design-based approach, inference relies on random sampling. In the model-based approach, inference relies on distributional assumptions. We compare the approaches for finite population spatial data.
  2. We provide relevant background for the design-based and model-based approaches and then study their performance using simulated and real data. In the simulated and real data, a variety of sample sizes, location layouts, dependence structures, and response types are considered. The population mean is the parameter of interest and performance is measured using statistics like bias, squared error, and interval coverage.
  3. When studying the simulated and real data, we found that regardless of the strength of spatial dependence in the data, the generalized random tessellation stratified (GRTS) algorithm, which explicitly incorporates spatial locations into sampling, tends to outperform the simple random sampling (SRS) algorithm, which does not explicitly incorporate spatial locations into sampling. We also found that model-based approaches tend to outperform design-based approaches, even for skewed data where the model-based distributional assumptions are violated. The performance gap between these approaches is small GRTS samples are used but large when SRS samples are used. This suggests that the sampling choice (whether to use GRTS or SRS) is most important when performing design-based inference.
  4. There are many benefits and drawbacks to the design-based and model-based approaches for finite population spatial data that practitioners must consider when choosing between them. We provide relevant background contextualizing each approach and study their properties in a variety of scenarios, making recommendations for use based on the practitioner's goals.
journal: "Methods in Ecology and Evolution"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
linenumbers: true
numbersections: true
csl: elsevier-harvard.csl
preamble: >
  \usepackage{bm}
  \usepackage{bbm}
  \usepackage{color}
  \DeclareMathOperator{\var}{{var}}
  \DeclareMathOperator{\cov}{{cov}}
  \usepackage{caption}
  \usepackage{subcaption}
  \usepackage{setspace}
  \usepackage{fancyhdr}
  \pagestyle{fancy}
  \fancyhf{}
  \chead{Spatial design-based vs model-based}
  \doublespacing
output: rticles::elsevier_article
---

# Keywords {.unnumbered}

Design-based inference; Finite population block kriging (FPBK); Generalized random tessellation stratified (GRTS) algorithm; Local neighborhood variance estimator; Model-based inference; Restricted maximum likelihood (REML) estimation; Spatially balanced sampling; Spatial covariance 

# Introduction {#sec:introduction}

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  warning = FALSE, 
  message = FALSE,
  include = TRUE, 
  echo = FALSE
)
library(tidyverse)
library(here)
library(xtable) # latex tables
```

<!-- Brief introduction to model based and design based -->

When data cannot be collected for all units in a population (i.e., population units), data are collected on a subset of the population units -- this subset is called a sample. There are two general approaches for using samples to make frequentist statistical inferences about a population: design-based and model-based.  In the design-based approach, inference relies on randomly assigning some population units to be in the sample (random sampling). Alternatively, in the model-based approach, inference relies on distributional assumptions about the underlying stochastic process generating the sample. Each paradigm has a deep historical context [@sterba2009alternative] and its own set of benefits and drawbacks [@hansen1983evaluation, @brus1997random]. In this manuscript, we compare the design-based and model-based approaches for finite population spatial data.

<!-- Shift focus to spatial data -->

Spatial data are data that have some sort of spatial index, usually via coordinates. @de1990model and @brus1993design give early comparisons of design-based and model-based approaches for spatial data, quashing the belief that design-based approaches could not be used for spatially correlated data. Since then, there have been several general comparisons between design-based and model-based approaches for spatial data [@brus1997random; @verhoef2002sampling; @verhoef2008spatial; @brus2021statistical]. @cooper2006sampling reviews the two approaches in an ecological context before introducing a "model-assisted" variance estimator that combines aspects from each approach. In addition to @cooper2006sampling, there has been substantial research and development into estimators that use both design-based and model-based principles (see e.g., @sterba2009alternative and @cicchitelli2012model, and for Bayesian approaches, see @chan2020bayesian and @hofman2021many).

<!-- Paragraph about the contribution of the manuscript and outlining the rest -->
While comparisons between design-based and model-based approaches have been studied in spatial contexts, our contribution is comparing design-based approaches specifically built for spatial data to model-based approaches. Though the broad comparisons we draw between design-based and model-based approaches generalize to finite and infinite populations, we focus on finite populations.  A finite population contains a finite number of population units (we assume the finite number is known); an example is lakes (treated as a whole with the lake centroid representing location) in the conterminous United States.  An infinite population contains an infinite number of population units; an example is locations within a single lake. 

The rest of the manuscript is organized as follows. In Section \ref{sec:background}, we introduce and provide relevant background for design-based and model-based approaches to finite population spatial data. In Section \ref{sec:mm}, we describe how we intend to compare performance of the approaches using simulated and real data. In Section \ref{sec:results}, we present analysis reslts for the simulated and real data. And in Section \ref{sec:discussion}, we end with a discussion and provide directions for future research. 

## Background {#sec:background}

The design-based and model-based approaches incorporate randomness in fundamentally different ways. In this section, we describe the role of randomness for each approach and the subsequent effects on statistical inferences for spatial data.

### Comparing Design-Based and Model-Based Approaches {#subsec:dvm_compare}

The design-based approach assumes the population is fixed. Randomness is incorporated via the selection of population units according to a sampling design. A sampling
design assigns a probability of selection to each sample (subset of population
units). Some examples of commonly used sampling designs include simple random sampling, stratified random sampling, and cluster sampling. The inclusion probability of a population unit follows by summing each sample's probability of selection over all samples that contain the population unit. Inclusion probabilities are later used to estimate population parameters. 

When samples are chosen in a manner such that the layout of sampled units reflects the layout of the population units, we call the resulting sample spatially balanced. By "reflecting the layout of the population units", we mean that if population units are concentrated in specific areas, the units in the sample should be concentrated in the same areas. Because spatially balanced samples reflect the layout of the population units, they are not necessarily spread out in space in some equidistant manner. One approach to selecting spatially balanced samples is the generalized random tessellation stratified (GRTS) algorithm [@stevens2004spatially], which we discuss in more detail in Section \ref{subsec:spb_design}. 

Fundamentally, the design-based approach combines the randomness of the sampling design with the data collected via the sample to justify the estimation and uncertainty quantification of fixed, unknown parameters of a population (e.g., a population mean). Treating the data as fixed and incorporating randomness through the sampling design yields estimators having very few other assumptions. Confidence intervals for these types of estimators are typically derived using limiting arguments that incorporate all possible samples. Sample means, for example, are asymptotically normal (Gaussian) by the Central Limit Theorem (under some assumptions). If we repeatedly select samples from the population, then 95% of all 95% confidence intervals constructed from a procedure with appropriate coverage will contain the true fixed population mean. @sarndal2003model and @lohr2009sampling provide thorough reviews of the design-based approach.

The model-based approach assumes the population is a random realization of a data-generating stochastic process. Randomness is formally incorporated through distributional assumptions on this process. Strictly speaking, randomness need not be incorporated through random sampling, though @diggle2010geostatistical warn against preferential sampling. Preferential sampling occurs when the process generating the data locations and the process being modeled are not independent of one another. To guard against preferential sampling, model-based approaches can implement some form of random sampling, though it is common for model-based approaches to sample non-randomly. When model-based approaches do implement random sampling, the inclusion probabilities are ignored when analyzing the sample (in contrast to the design-based approach, which relies on these inclusion probabilities to analyze the sample).

Instead of estimating fixed, unknown population parameters, as in the design-based approach, often the goal of model-based inference is to predict a realized variable. For example, suppose the realized mean of all population units (the realized population mean) is the variable of interest. Instead of a fixed, unknown mean, we are predicting the value of the mean, a random variable. Prediction intervals are then derived using assumptions of the data-generating stochastic process. If we repeatedly generate realizations from the same process and select samples, then 95% of all 95% prediction intervals constructed from a procedure with appropriate coverage will contain their respective realized means. @cressie1993statistics and @schabenberger2017statistical provide thorough reviews of model-based approaches for spatial data. In Fig. \ref{fig:fig1}, we provide a visual comparison of the design-based and model-based approaches (@verhoef2002sampling and @brus2021statistical provide similar figures). This figure contrasts the design-based approach with a fixed population and random sampling to the model-based approach with random populations and non-random sampling.

\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/dvm_comp.jpeg}
  \caption{A visual comparison of the design-based and model-based approaches. In the top row, the design-based approach is highlighted. There is one fixed population with nine population units and three random samples of size four (points circled are those sampled). The response values at each site are fixed. In the bottom row, the model-based approach is highlighted. There are three realizations of the same data-generating stochastic process that are all sampled at the same four locations. The response values at each site are random.}
  \label{fig:fig1}
\end{figure}

### Spatially Balanced Design and Analysis {#subsec:spb_design}

We previously mentioned that the design-based approach can be used to select spatially balanced samples. Spatially balanced samples are useful because parameter estimates from these samples tend to vary less than parameter estimates from samples lacking spatial balance [@stevens2004spatially; @barabesi2011sampling; @grafstrom2013well; @robertson2013bas; @wang2013design; @benedetti2017spatiallyreview]. The first spatially balanced sampling algorithm to see widespread use was the generalized random tessellation stratified (GRTS) algorithm [@stevens2004spatially]. To quantify the spatial balance of a sample, @stevens2004spatially proposed loss metrics based on Voronoi polygons (i.e., Dirichlet Tessellations). After the GRTS algorithm was developed, several other spatially balanced sampling algorithms emerged, including stratified sampling with compact geographical strata @walvoort2010r, the local pivotal method [@grafstrom2012spatially; @grafstrom2018spatially], spatially correlated Poisson sampling [@grafstrom2012spatiallypoisson], balanced acceptance sampling [@robertson2013bas], within-sample-distance sampling [@benedetti2017spatially], and Halton iterative partitioning sampling [@robertson2018halton]. In this manuscript, we select spatially balanced samples using the GRTS algorithm because it is readily available in the `spsurvey` \textbf{\textsf{R}} package [@dumelle2022spsurvey] and naturally accommodates finite and infinite sampling frames, unequal inclusion probabilities, and replacement units. Replacement units are additional population units that can be sampled when a population unit originally selected can no longer be sampled. A couple reasons why an originally selected site can no longer be sampled include its location being physically inaccessible or on private land that the researcher does not have permission to access.

The GRTS algorithm selects samples by utilizing a particular mapping between two-dimensional and one-dimensional space that preserves proximity relationships. First the bounding box of the domain is split up into four distinct, equally sized squares called level-one cells. Each level-one cell is randomly assigned a level-one address of 0, 1, 2, or 3. The set of level-one cells is denoted by $\mathcal{A}_1$ and defined as $\mathcal{A}_1 \equiv \{a_1: a_1 = 0, 1, 2, 3\}$. Within each level-one cell, the inclusion probability for each population unit is summed, and if any of these sums exceed one, a second level of cells is added. Then each level-one cell is split into four distinct, equally sized squares called level-two cells. Each level-two cell is randomly assigned a level-two address of 0, 1, 2, or 3. The set of level-two cells is denoted by $\mathcal{A}_2$ and defined as $\mathcal{A}_2 \equiv \{a_1a_2: a_1 = 0, 1, 2, 3; a_2 = 0, 1, 2, 3\}$. The inclusion probabilities within each level-two cell are summed, and if any of these sums exceed one, a third level of cells is added. This process continues for $k$ steps, until all level-$k$ cells have inclusion probability sums no larger than one. Then $\mathcal{A}_k \equiv \{a_1...a_k : a_1 = 0, 1, 2, 3; ...; a_k = 0, 1, 2, 3\}$.

After determining $\mathcal{A}_k$, it is placed into hierarchical order. Hierarchical order is a numeric order that first sorts $\mathcal{A}_k$ by the level-one addresses from smallest to largest, then sorts $\mathcal{A}_k$ by the level-two addresses from smallest to largest, and so on. For example, $\mathcal{A}_2$ in hierarchical order is the set \linebreak $\{00, 01, 02, 03, 10, ..., 13, 20, ..., 23, 30, ..., 33\}$. Because hierarchical ordering sorts by level-one cells, then level-two cells, and so on, population units that have similar hierarchical addresses tend to be nearby one another in space. Next each population unit is mapped to a one-dimensional line in hierarchical order where each population unit's inclusion probability equals its line-length. If a level-$k$ cell has multiple population units in it, they are randomly placed within the cell's respective line segment. A uniform random variable is then simulated in $[0, 1]$ and a systematic sample is selected on the line, yielding $n$ sample points for a sample size $n$. Each of these sample points falls on some population unit's line segment, and thus that population unit is selected in the sample. For further details regarding the GRTS algorithm, see @stevens2004spatially. 

After selecting a sample and collecting data, unbiased estimates of population means and totals can be obtained using the Horvitz-Thompson estimator [@horvitz1952generalization]. If $\tau$ is a population total, the Horvitz-Thompson estimator for $\tau$, denoted by $\hat{\tau}_{ht}$, is is given by
\begin{align}\label{eq:ht}
  \hat{\tau}_{ht} = \sum_{i = 1}^n z_i \pi_i^{-1},
\end{align}
where $z_i$ is the value of the $i$th population unit in the sample, $\pi_i$ is the inclusion probability of the $i$th population unit in the sample, and $n$ is the sample size. An estimate of the population mean is obtained by dividing $\hat{\tau}_{ht}$ by $N$, the number of population units. 

It is also important to quantify the uncertainty in $\hat{\tau}_{ht}$.  @horvitz1952generalization and @sen1953estimate provide variance estimators for $\hat{\tau}_{ht}$, but these estimators have two drawbacks. First, they rely on calculating $\pi_{ij}$, the probability that population unit $i$ and population unit $j$ are both in the sample -- this quantity can be challenging if not impossible to calculate analytically for GRTS samples. Second, these estimators tend to ignore the spatial locations of the population units. To address these two drawbacks simultaneously, @stevens2003variance proposed the local neighborhood variance estimator. The local neighborhood variance estimator does not rely on $\pi_{ij}$ and estimates the variance of $\hat{\tau}$ conditional on the random properties of the GRTS sample -- the idea being that this conditioning should yield a more precise estimate of $\hat{\tau}$. They show that the contribution from each sample unit (population unit in the sample) to the overall variance is dominated by local variation. Thus the local neighborhood variance estimator is a weighted sum of variance estimates from each sample unit's local neighborhood. These local neighborhoods contain the sample unit itself and its three nearest neighbors among all other sample units. For more details, see @stevens2003variance. 

### Finite Population Block Kriging

Finite population block kriging (FPBK) is a model-based approach that expands the geostatistical Kriging framework to the finite population setting [@verhoef2008spatial]. Instead of developing inference based on a specific sampling design, we assume the data are generated by a spatial stochastic process. We summarize some of the basic principles of FPBK next -- for more details, see @verhoef2008spatial. Let ${\mathbf{z} \equiv \{\text{z}(s_1), \text{z}(s_2), . . . , \text{z}(s_N) \}}$ be an $N \times 1$ response vector at locations $s_1$, $s_2$, . . . , $s_N$ that can be measured at the $N$ population units. Suppose we want to use a sample to predict some linear function of the response variable, $f(\mathbf{z}) = \mathbf{b}^\prime \mathbf{z}$, where $\mathbf{b}^\prime$ is a $1 \times N$ vector of weights (e.g, the population mean is represented by a weights vector whose elements all equal $1 / N$). Denoting quantities that are part of the sampled population units with a subscript \emph{s} and quantities that are part of the unsampled population units with a subscript \emph{u}, let

\begin{equation}
\begin{pmatrix} \label{equation:Zmarginal}
    \mathbf{z}_s      \\
    \mathbf{z}_u
\end{pmatrix}
=
\begin{pmatrix}
  \mathbf{X}_s    \\
  \mathbf{X}_u
\end{pmatrix}
\bm{\beta} +
\begin{pmatrix}
\bm{\delta}_s    \\
\bm{\delta}_u
\end{pmatrix},
\end{equation}
where $\mathbf{X}_s$ and $\mathbf{X}_u$ are the design matrices for the sampled and unsampled population units, respectively, $\bm{\beta}$ is the parameter vector of fixed effects, and $\bm{\delta} \equiv [\bm{\delta}_s \,\, \bm{\delta}_u]'$, where $\bm{\delta}_s$ and $\bm{\delta}_u$ are random errors for the sampled and unsampled population units, respectively. 

FPBK assumes $\bm{\delta}$ in Equation$~$\ref{equation:Zmarginal} has mean-zero and a spatial dependence structure that can be modeled using a covariance function. This covariance function is commonly assumed to be non-negative, second-order stationary (depending only on the separation vector (e.g., distance) between population units), isotropic (independent of direction), and decay with distance between population units [@cressie1993statistics]. Henceforth, it is implied that we have made these same assumptions regarding $\bm{\delta}$, though @chiles1999geostatistics, pp. 80-93 discuss covariance functions that are not second-order stationary, not isotropic, or not either. A variety of flexible covariance functions can be used to model $\bm{\delta}$ [@cressie1993statistics]; one example is the exponential covariance function (@cressie1993statistics provides a thorough list of spatial covariance functions). The $i,j$th element of the exponential covariance matrix, $\cov(\bm{\delta})$, is
\mbox{}
\begin{align}\label{equation:expcov}
\cov(\delta_i, \delta_j) = 
\begin{cases} 
\sigma^2_{1}\exp(-h_{i,j}/\phi) & h_{i,j} > 0 \\
\sigma^2_{1} + \sigma^2_2 & h_{i,j} = 0
\end{cases}
,
\end{align}
where $\sigma^2_{1}$ is the variance parameter that quantifies the spatially dependent variability, $\sigma^2_{2}$ is the variance parameter the quantifies that spatially independent variability, $\phi$ is the distance parameter that measures the distance-decay rate of the covariance, and $h_{i,j}$ is the Euclidean distance between population units $i$ and $j$. In geostatistical literature, $\sigma^2_{1}$ is often called the partial sill, $\sigma^2_{2}$ is often called the nugget, and $\phi$ is often called the range. 

The parameters in Equation$~$\ref{equation:Zmarginal} can be estimated using a variety of techniques, but we focus on using restricted maximum likelihood [@patterson1971recovery; @harville1977maximum; @wolfinger1994computing]. REML is preferred over maximum likelihood (ML) because ML estimates can be badly biased for small sample sizes, due to the fact that ML makes no adjustment for the simultaneous estimation of $\bm{\beta}$ and $\bm{\delta}$ [@patterson1971recovery].  Minus twice the REML log-likelihood of the sampled sites is given by
\begin{equation}\label{equation:reml}
  \ln|\bm{\Sigma}| + (\bm{z}_s - \bm{X}_s \bm{\tilde{\beta}})^T \bm{\Sigma}_{ss}^{-1}(\bm{z}_s - \bm{X}_s \bm{\tilde{\beta}}) + \ln|\bm{X}_s^T \bm{\Sigma}_{ss}^{-1} \bm{X}_s| + (n - p) \ln(2 \pi) ,
\end{equation}
where $\bm{\tilde{\beta}} = (\bm{X}_s^T \bm{\Sigma}_{ss}^{-1} \bm{X}_s)^{-1} \bm{X}_s^T \bm{\Sigma}_{ss}^{-1} \bm{z}_s$ and $\bm{\Sigma}_{ss}$  is the covariance matrix of the sampled sites. Minimizing Equation$~$\ref{equation:reml} yields $\bm{\hat{\delta}}_{reml}$, the REML estimates of $\bm{\delta}$. Then $\bm{\beta}_{reml}$, the REML estimate of $\bm{\beta}$, is given by $(\bm{X}_s^T \bm{\hat{\Sigma}}_{ss}^{-1} \bm{X})^{-1} \bm{X}_s^T \bm{\hat{\Sigma}}_{ss}^{-1} \bm{z}_s$, where $\bm{\hat{\Sigma}}_{ss}$ is $\bm{\Sigma}_{ss}$ evaluated at $\bm{\hat{\delta}}_{reml}$.

With the model formulation in Equation$~$\ref{equation:Zmarginal}, the Best Linear Unbiased Predictor (BLUP) for $f(\mathbf{b}'\mathbf{z})$ and its prediction variance can be computed. While details of the derivation are in @verhoef2008spatial, we note here that the predictor and its variance are both moment-based, meaning that they do not rely on any distributional assumptions. Distributional assumptions are used, however, when constructing prediction intervals.

Other approaches, such as k-nearest-neighbors [@fix1989discriminatory; @ver2013comparison] and random forest [@breiman2001random], among others, could also be used to obtain predictions for a mean or total from finite population spatial data. Compared to the k-nearest-neighbors and random forest approach, we prefer FPBK because it is model-based and relies on theoretically-based variance estimators leveraging the model's spatial covariance structure, whereas k-nearest-neighbors and random forests use ad-hoc variance estimators [@ver2013comparison]. Additionally, @ver2013comparison compared FPBK, k-nearest-neighbors, and random forest in a variety of spatial data contexts, and FPBK tended to perform best. 

# Materials and Methods {#sec:mm}

In this section we describe how we used simulated and real data to investigate performance between simple random sampling without replacement (SRS) and GRTS sampling as well as performance between design-based (DB) and model-based (MB) inference. In SRS and GRTS sampling, all population units had equal inclusion probabilities. The important distinction between SRS and GRTS is that SRS ignores spatial locations while sampling but GRTS explicitly incorporates them. Together, the two sampling plans (SRS and GRTS) combined with the two inference approaches (DB and MB) yielded four sampling-inference combinations: SRS-DB, SRS-MB, GRTS-DB, and GRTS-MB. For SRS-DB, the Horvitz-Thompson estimator \eqref{eq:ht} was used to estimate means and the commonly-used SRS variance formula [@sarndal2003model; @lohr2009sampling] was used to estimate the variance. This variance formula is given by
\begin{equation}\label{equation:srs_var}
 \frac{f[\sum_{i = 1}^n (z_i - \bar{z})^2]}{n(n - 1)},
\end{equation}
where $z_i$ is the $i$th response value, $\bar{z}$ is the mean of all $z_i$, $n$ is the sample size, $N$ is the population size, and $f = (1 - n / N)$ ($f$ is often called the finite population correction factor). For GRTS-DB, the Horvitz-Thompson esetimator was used to estimate means and the local neighborhood variance was used to estimate variances. For SRS-MB and GRTS-MB, FPBK was used to estimate means and variances and parameters were estimated using restricted maximum likelihood.

We used simulated data to compare the sampling-inference combinations across many realized populations from the same data-generating stochastic process. With the simulated data, we were in control of the data-generating stochastic process and the random sampling process. We used real data from the 2012 National Lakes Assessment [@USEPA2012NLA] to compare the sampling-inference combinations within a single realized population (which is typically the case in reality). With the real data, we were in control of only the random sampling process.

## Simulated Data {#sec:mm_sim}

```{r, echo = FALSE, results = "asis"}
# tab <- matrix(c("IRS-Design", "IRS-Model", "GRTS-Design", "GRTS-Model"),
#        nrow = 2, byrow = TRUE) %>%
#   as.table()
# row.names(tab) <- c("IRS", "GRTS")
# xtab1 <- xtable(tab, col.names = c("Design", "Model"), caption = "\\label{tab:designanalysis} Sampling-inference combinations in the simulation study. The rows give the two types of sampling designs and the columns give the two types of analyses.")
# align(xtab1) <- "r|ll"
# names(xtab1) <- c("Design", "Model")
# print(xtab1, comment = FALSE)
# ## I really want "Analysis" to appear as a row header and "Sampling Design" 
# ## to appear as a column header, but this isn't easy to figure out.
# ## I couldn't figure this out with xtable either so it might need to be
# ## made "by hand."
```

CHANGE LOGNORMAL VERBAGE TO SKEWED -- look for DRE acronym

We evaluated performance of the four sampling-inference combinations in 36 different simulation scenarios. The 36 scenarios resulted from the crossing of three sample sizes, two location layouts (of the population units), two response types, and three proportions of dependent random error (DRE). The three sample sizes ($n$) were $n = 50, n = 100,$ and $n = 200$. Samples were always selected from a population size ($N$) of $N = 900$. The two location layouts were random and gridded. Locations in the random layout were randomly generated inside the unit square ($[0, 1] \times [0, 1]$). Locations in the gridded layout were placed on a fixed, equally spaced grid inside the unit square. The two response types were normal and skewed. For the normal response type, the response was simulated using mean-zero random errors with the exponential covariance (Equation$~$\ref{equation:expcov}) for three proportions of dependent random error (DRE): 0% DRE, 50% DRE, and 90% DRE. Recall the proportion of DRE is represented by $\sigma^2_1 / (\sigma^2_1 + \sigma^2_2)$, where $\sigma^2_1$ and $\sigma^2_2$ are the DRE variance and independent random error (IRE) variance from Equation$~$\ref{equation:expcov}, respectively. The total variance, $\sigma^2_1 + \sigma^2_2$, was always 2. The distance parameter was always $\sqrt{2} / 3$, chosen so that the correlation in the DRE decayed to nearly zero at $\sqrt{2}$, the largest possible distance between two population units in the domain. For the skewed response type, the response was first simulated using the same approach as for the normal response type, except that the total variance was 0.6931 instead of 2. The response was then exponentiated, yielding a skewed random variable whose total variance was 2. The skewed responses were used to evaluate performance of the sampling-inference approaches for data that were not normal but were still estimated using REML, which relies on a normal log-likelihood. Figure \ref{fig:sim_pops} shows an example of a realized population for the normal and skewed responses using the random layout and 50% DRE. 

\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/symm_pop_hist.jpeg}
  \caption{Histogram of a realized population for the normal response.}
  \label{fig:symm_pop_hist}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/skew_pop_hist.jpeg}
  \caption{Histogram of a realized population for the skewed response.}
  \label{fig:skew_pop_hist}
\end{subfigure}
\caption{Histograms of realized populations simulated for the normal and skewed resposnes using the random layout and 50\% DRE.}
\label{fig:sim_pops}
\end{figure}

```{r, echo = FALSE, results = "asis"}
# n <- c("50", "100", "200")
# site_locations <- c("Random", "Gridded", "")
# psill_ratio <- c("0", "0.5", "0.9")
# resp_type <- c("Normal", "Lognormal", "")
# parm_tab <- rbind(n, site_locations, psill_ratio, resp_type)
# parm_tab[c(2, 4), 3] <- "-"
# row.names(parm_tab) <- c("Sample Size (n)", "Location Layout", 
#                          "Proportion of Dependent Error", "Response Type")
# # parm_tab <- parm_tab[c(1, 2, 4, 3), ]
# parm_xtab <- xtable(parm_tab, caption = "\\label{tab:parmtab} Simulation scenario options. All combinations of sample size, location layout, response type, and proportion of dependent random error composed the 36 simulation scenarios. In each simualtion scenario, the total variance was 2.")
# align(parm_xtab) <- "r|lll"
# print(parm_xtab, include.colnames = FALSE, hline.after = c(0, nrow(parm_xtab)), comment = FALSE)
```

In each of the 36 simulation scenarios, there were 2000 independent simulation trials. Within each simulation scenario and trial, IRS and GRTS samples were selected and then design-based and model-based analyses were used to estimate (design-based) or predict (model-based) the mean and construct 95% confidence (design-based) or 95% prediction (model-based) intervals. With the model-based analyses, covariance parameters were estimated (using REML) separately for each trial.  After all 2000 trials, we summarized the long-run performance of the sampling-inference combination in each scenario by calculating mean bias, root-mean-squared error, and interval coverage. Mean bias is taken as the average deviation between each trial's estimated (or predicted) mean and its realized mean: $\frac{1}{n}\sum_{i = 1}^{2000} (\hat{\mu}_i - \mu_i)$, where $i$ indexes simulation trials. Root-mean-squared error is taken as the square root of the average squared deviation between each trial's estimated (or predicted) mean and its realized mean: $\sqrt{\frac{1}{n}\sum_{i = 1}^{2000} (\hat{\mu}_i - \mu_i)^2}$. Interval coverage is taken as the proportion of simulation trials where the realized mean is contained in its 95% confidence (or prediction) interval. These intervals are constructed using the normal distribution -- justification comes from the asymptotic normality of means via the central limit theorem (under some assumptions). Quantifying these metrics is important because together, they give us an idea of the accuracy (mean bias), spread (RMSE), and validity (interval coverage) of the sampling-inference combinations.

## National Lakes Assessment Data {#sec:mm_app}

The United States Environmental Protection Agency (USEPA), states, and tribes periodically conduct National Aquatic Research Surveys (NARS) to assess the water quality of various bodies of water in the contiguous United States. One component of NARS is the National Lakes Assessment (NLA), which measures various aspects of lake health and water quality. We will analyze mercury concentration data collected at 986 lakes from the 2012 NLA. Although we can calculate the true mean mercury concentration values for these 986 lakes, here we will explore whether or not we can obtain an adequately precise estimate (design-based) or prediction (model-based) for the realized mean mercury concentration if we sample only 100 of the 986 lakes. For each of the four familiar sampling-inference combinations (IRS-Design, IRS-Model, GRTS-Design, and GRTS-Model), we estimate (design-based) or predict (model-based) the mean mercury concentration and construct 95% intervals from this sample of 100 lakes and compare to the true mean mercury concentration from all 986 lakes.

# Results {#sec:results}

## Simulated Data {#sec:r_sim}

The mean bias was nearly zero for all four sampling-inference combinations in all 36 scenarios, so we omit a more detailed summary of those results here. Tables for mean bias in all 36 simulation scenarios are provided in the supporting information.

Fig. \ref{fig:rmspe_eff} shows the relative rMS(P)E of the four sampling analysis combinations using the random location layout with "IRS-Design" as the baseline. The relative rMS(P)E is defined as
\begin{equation*}
\frac{\text{rMS(P)E of sampling-inference combination}}{\text{rMS(P)E of IRS-Design}},
\end{equation*}
When there is no spatial covariance (Fig. \ref{fig:rmspe_eff}, "Prop DE: 0" row), the four sampling-inference combinations have approximately equal rMS(P)E. In these scenarios, using the GRTS algorithm or a model-based analysis does not increase efficiency compared to IRS-Design. When there is spatial covariance (Fig. \ref{fig:rmspe_eff}, "Prop DE: 0.5" and "Prop DE: 0.9" rows), GRTS-Model tends to have the lowest rMS(P)E, followed by GRTS-Design, IRS-Model, and finally IRS-Design, though the difference in relative rMS(P)E among GRTS-Model, GRTS-Design, and IRS-Model is relatively small.  As the strength of spatial covariance increases, the gap in rMS(P)E between IRS-Design and the other sampling-inference combinations widens. Finally we note that when there is spatial covariance, IRS-Model has a much lower rMS(P)E than IRS-Design, suggesting that the poor design properties of IRS are largely mitigated by the model-based analysis. These rMS(P)E conclusions are similar to those observed in the grid location layout, so we omit a grid location layout figure here. Tables for rMS(P)E in all 36 simulation scenarios are provided in the supporting information.
\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/rmspe_eff.jpeg}
  \caption{Relative rMS(P)E in the simulation study for the four sampling-inference combinations. The rows indicate the proportion of dependent error and the columns indicate the response type.}
  \label{fig:rmspe_eff}
\end{figure} 

Fig. \ref{fig:mse_eff} shows the relative MStdE of the four sampling-inference combinations using the random location layout with "IRS-Design" as the baseline. The relative MStdE is defined as
\begin{equation*}
\frac{\text{MStdE of sampling-inference combination}}{\text{MStdE of IRS-Design}},
\end{equation*}
Many general takeaways regarding MStdE are similar to general takeaways regarding rMS(P)E: there seems to be no benefit to using IRS, even when there is no spatial covariance; as the strength of spatial covariance increases, the gap in MStdE between IRS-Design and the other sampling-inference combinations widens; and IRS-Model outperforms IRS-Design by a noticeable margin. These fact that the rMS(P)E and MStdE findings are similar is not particularly surprising because the mean bias for all sampling-inference combinations was nearly zero, thus rMS(P)E is driven by the standard error of the estimators (design-based) or predictors (model-based). We do note that between GRTS-Design and GRTS-Model, GRTS-Design had lower MStdE when there was no spatial covariance or a medium amount of spatial covariance (Fig. \ref{fig:mse_eff}, "Prop DE: 0" and "Prop DE: 0.5" rows), and GRTS-Model had lower MStdE when there was a high amount of spatial covariance (Fig. \ref{fig:mse_eff}, "Prop DE: 0.9" row). These MStdE conclusions are similar to those observed in the grid location layout, so we omit a grid location layout figure here. Tables for MStdE in all 36 simulation scenarios are provided in the supporting information.

Fig. \ref{fig:figconf} shows the 95% interval coverage for each of the four sampling-inference combinations in the random location layout. Within each scenario, the sampling-inference combinations tend to have fairly similar interval coverage, though when $n = 50$ or $n = 100$, GRTS-Design coverage is usually a few percentage points lower than the other combinations. Coverage in the normal response scenarios was usually near 95%, while coverage in the lognormal response scenarios usually varied from 90% to 95% but increased with the sample size. At a sample size of 200, all four sampling-inference combinations had approximately 95% interval coverage in both response scenarios for all dependent error proportions.  These interval coverage conclusions are similar to those observed in the grid location layout, so we omit a grid location layout figure here. Tables for interval coverage in all 36 simulation scenarios are provided in the supporting information.
\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/coverage.jpeg}
  \caption{Interval coverage in the simulation study for the four sampling-inference combinations. The rows indicate the proportion of dependent error and the columns indicate the response type. The solid, black line represents 95\% coverage.}
  \label{fig:figconf}
\end{figure}

## National Lakes Assessment DAta {#sec:r_app}

USE MERCURY UNITS

Fig. \ref{fig:merc} shows a map and histogram of mercury concentration in all 986 NLA lakes. The map shows mercury concentration exhibits some spatial patterning, with high mercury concentrations in the northeast and north central United States. The histogram shows that mercury concentration is right-skewed, with most lakes having a low value of mercury concentration but a few having a much higher concentration.  Fig. \ref{fig:merc} also shows mercury concentration's empirical semivariogram. The empirical semivariogram can be used as a tool to visualize spatial dependence. It quantifies the mean of the halved squared differences (semivariance) among all pairs of mercury concentrations at different distances apart. When a process has spatial covariance (exhibits spatial dependence), the mean semivariance tends to be smaller at small distances and larger at large distances. The empirical semivariogram in Fig. \ref{fig:merc} suggests that mercury concentration exhibits spatial dependence. Lastly we note that the true mean mercury concentration in the 986 NLA lakes is 103.2 ng / g.

We selected a single IRS sample and a single GRTS sample and estimated (design-based) or predicted (model-based) the mean mercury concentration and constructed 95% confidence (design-based) and 95% (model-based) prediction intervals. For the model-based analyses, the exponential covariance was used. Table \ref{tab:appliedtab} shows the results from these analyses. Though we should not generalize these results to other samples from this population, we do mention a few findings. First, IRS-Design has the largest standard error. Second, compared to IRS-Design and IRS-Model, GRTS-Design and GRTS-Model are much closer to the true mean mercury concentration (have bias closer to zero) and have much lower standard errors (more precise intervals). Third, GRTS-Model has the least amount of bias and the lowest standard error (most precise interval). Finally, we note that for all sampling-inference combinations, the true mean mercury concentration (103.2 ng / g) is within the bounds of the combination's 95% interval.

```{r apptab, results = "asis"}
res_df <- readr::read_csv(here("inst", "output", "application", "application.csv"))
# res_df$bias <- res_df$realized_mean - res_df$estimate
# res_df_drop <- res_df[ , c("approach", "estimate", "bias", "se", "lb", "ub")]
res_df_drop <- res_df[, ]
names(res_df_drop) <- c("Approach", "True Mean", "Est/Pred", "SE", "95% LB", "95% UB")
xtab_app <- xtable(res_df_drop, digits = 1, caption = "\\label{tab:appliedtab} For each sampling-inference combination (Approach), the true mean mercury concentration (True Mean), estimates/predictions (Est/Pred), standard errors (SE), lower 95\\% interval bounds (95\\% LB), and upper 95\\% interval bounds (95\\% UB) for mean mercury concentration computed using a sample of 100 lakes in the NLA data.")
print(xtab_app, include.rownames = FALSE, comment = FALSE)
```

## New Application


\begin{figure}
\centering
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/zmmi_map.jpeg}
  \caption{Spatial map of the ZMMI population.}
  \label{fig:zmmi_map}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/mercury_map.jpeg}
  \caption{Spatial map of mercury (Hg) population.}
  \label{fig:mercury_map}
\end{subfigure} \\
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/zmmi_hist.jpeg}
  \caption{Histogram of the ZMMI population.}
  \label{fig:zmmi_hist}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/mercury_hist.jpeg}
  \caption{Histogram of the mercury (Hg) population.}
  \label{fig:mercury_hist}
\end{subfigure} \\
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/zmmi_sv.jpeg}
  \caption{Semivariogram of the ZMMI population.}
  \label{fig:zmmi_sv_plot}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/mercury_sv.jpeg}
  \caption{Semivariogram of the mercury (Hg) population.}
  \label{fig:mercury_sv_plot}
\end{subfigure}
\caption{Exploratory graphics of the ZMMI and mercury (Hg) populations in the National Lakes Assessment (NLA) 2012 data.}
\label{fig:zmmi}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/data_rmspe_eff.jpeg}
  \caption{Relative rMS(P)E in the data study for the four sampling-inference combinations. The rows indicate the proportion of dependent error and the columns indicate the response type.}
  \label{fig:data_rmspe_eff}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/data_coverage.jpeg}
  \caption{Interval coverage in the data study for the four sampling-inference combinations. The rows indicate the proportion of dependent error and the columns indicate the response type. The solid, black line represents 95\% coverage.}
  \label{fig:data_figconf}
\end{figure}

# Discussion {#sec:discussion}

ADD EXTRAS LIKE ANISOTROPY AND UNEQUAL INCLUSION PROBABILITIES

The design-based and model-based approaches to statistical inference are fundamentally different paradigms. The design-based approach relies on random sampling to estimate population parameters. The model-based approach relies on distributional assumptions to predict realized values of a stochastic process. Though the model-based approach does not rely on random sampling, it can still be beneficial as a way to guard against preferential sampling. While the design-based and model-based approaches have often been compared in the literature from theoretical and analytical perspectives, our contribution lies in studying them in a spatial context while implementing spatially balanced sampling and the design-based, local neighborhood variance estimator. Aside from the theoretical differences described, a few analytical findings from the simulation study are particularly notable. First, independent of the analysis approach, we found no reason to prefer IRS over GRTS when sampling spatial data -- GRTS-Design and GRTS-Model generally had similar rMS(P)E as their IRS counterparts when there was no spatial covariance and lower rMS(P)E than their IRS counterparts when there was spatial covariance. Second, the sampling decision (IRS vs GRTS) is most important when using a design-based analysis. Though GRTS-Model still had lower rMS(P)E than IRS-Model, the model-based analysis mitigated most of the rMS(P)E inefficiencies that result from the IRS samples lacking spatial balance. Third, as the strength of spatial covariance increases, the gap in rMS(P)E and MStdE between IRS-Design and the other sampling-inference combinations also increases, likely because IRS-Design is the only combination that ignores spatial locations in sampling and analysis. Fourth and finally, when the response was normal, interval coverage for all sampling-inference combinations was usually close to 95% for all sample sizes; when the response was lognormal, interval coverage for all sampling-inference combinations was usually between 90% and 95% and closest to 95% when $n = 200$.

AT LEAST HAVE DISCUSSION ABOUT MODEL BASED ASSUMPTIONS AND MOVE VALIDITY COMMENTS TO RESULTS SECTION.

There are several benefits and drawbacks of the design-based and model-based approaches for finite population spatial data. Some we have discussed, but others we have not, and they are worthy of consideration in future research.  Design-based approaches are often computationally efficient, while model-based approaches can be computationally burdensome, especially for likelihood-based estimation methods like REML that rely on inverting a covariance matrix. The design-based approach easily handles binary data through a straightforward application of the Horvitz-Thompson estimator. In contrast, analyzing binary data using a model-based approach generally requires a logistic mixed regression model, which can be challenging to estimate and interpret [@bolker2009generalized]. The design-based approach yields valid results because the sampling plan and inclusion probabilities are specified directly by the researcher, while the model-based approach may not yield valid results if the assumptions made do not not accurately capture reality. The model-based approach, however, can more naturally quantify the relationship between covariates (predictor variables) and the response variable. The model-based approach also yields estimated spatial covariance parameters, which help better understand the dependence structure in the process in study. Model selection is also possible using model-based approaches and criteria such as cross validation, likelihood ratio tests, or AIC [@akaike1974new]. Model-based approaches are capable of more efficient small-area estimation than design-based approaches by leveraging distributional assumptions in areas with few observed units. Model-based approaches can also compute unit-by-unit predictions at unobserved locations and use them to construct informative visualizations like smoothed maps. @brus1997random provide a more thorough discussion regarding the benefits and drawbacks of the two approaches. In short, when deciding whether the design-based or model-based approach is more appropriate to implement, the benefits and drawbacks of each approach should be considered alongside the particular goals of the study.

# Acknowledgments {.unnumbered}

We would like to thank the editors and anonymous reviewers for their thoughtful comments which greatly improved the manuscript.

The views expressed in this manuscript are those of the authors and do not necessarily represent the views or policies of the U.S. Environmental Protection Agency or the National Oceanic and Atmospheric Administration. Any mention of trade names, products, or services does not imply an endorsement by the U.S. government, the U.S. Environmental Protection Agency, or the National Oceanic and Atmospheric Administration. The U.S. Environmental Protection Agency and National Oceanic and Atmospheric Administration do not endorse any commercial products, services, or enterprises.

# Conflict of Interest Statement {.unnumbered}

There are no conflicts of interest for any of the authors.

# Author Contribution Statement {.unnumbered}

All authors conceived the ideas; All authors designed the methodology; MD and MH performed the simulations and analyzed the data; MD and MH led the writing of the manuscript; All authors contributed critically to the drafts and gave final approval for publication.

# Data and Code Availability {.unnumbered}

This manuscript has a supplementary \textbf{\textsf{R}} package that contains all of the data and code used in its creation. The supplementary \textbf{\textsf{R}} package is hosted on GitHub. Instructions for download at available at

[https://github.com/michaeldumelle/DvMsp](https://github.com/michaeldumelle/DvMsp).

If the manuscript is accepted, this repository will be archived in Zenodo.

# Supporting Information {.unnumbered}

In the supporting information, we provide tables of summary statistics for all 36 simulation scenarios.

# References {#references .unnumbered}

