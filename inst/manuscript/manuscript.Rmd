---
title: A comparison of design-based and model-based approaches for finite population spatial data.
author:
  - name: Michael Dumelle
    affiliation: USEPA
    footnote: 1
  - name: Matt Higham
    affiliation: STLAW
  - name: Jay M. Ver Hoef
    affiliation: NOAA
  - name: Anthony R. Olsen
    affiliation: USEPA
  - name: Lisa Madsen
    affiliation: OSU
address:
  - code: USEPA
    address: United States Environmental Protection Agency, 200 SW 35th St, Corvallis, Oregon, 97333
  - code: STLAW
    address: Saint Lawrence University Department of Mathematics, Computer Science, and Statistics, 23 Romoda Drive, Canton, New York, 13617
  - code: NOAA
    address: Marine Mammal Laboratory, Alaska Fisheries Science Center, National Oceanic and Atmospheric Administration, Seattle, Washington, 98115
  - code: OSU
    address: Oregon State University Department of Statistics, 239 Weniger Hall, Corvallis, Oregon, 97331
footnote:
    code: 1
    text: "Corresponding Author: Michael Dumelle (Dumelle.Michael@epa.gov)"
abstract: |
  The design-based and model-based approaches to frequentist statistical inference lie on fundamentally different foundations. In the design-based approach, inference depends on random sampling. In the model-based approach, inference depends on distributional assumptions. In this manuscript, we compare the approaches for finite population spatial data. We first provide relevant background for the approaches and then use a simulation study and an analysis of real mercury concentration data to numerically compare them. We find that sampling plans that incorporate spatial locations (spatially balanced samples) perform better than sampling plans ignoring spatial locations (non-spatially balanced samples), regardless of whether design-based or model-based approaches were used to analyze the data. We also find that within sampling plans, the model-based approaches often outperform design-based approaches, even for skewed data. This gap in performance is small when spatially balanced samples are used but large when non-spatially balanced samples are used.

journal: "Methods in Ecology and Evolution"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
linenumbers: true
numbersections: true
csl: elsevier-harvard.csl
preamble: >
  \usepackage{bm}
  \usepackage{bbm}
  \usepackage{color}
  \DeclareMathOperator{\var}{{var}}
  \DeclareMathOperator{\cov}{{cov}}
output: rticles::elsevier_article
---

# Introduction {#sec:introduction}

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  warning = FALSE, 
  message = FALSE,
  include = TRUE, 
  echo = FALSE
)
library(tidyverse)
library(here)
library(xtable) # latex tables
```

<!-- Brief introduction to model based and design based -->

There are two general approaches for using data to make frequentist statistical inferences about a population: design-based and model-based. When data cannot be collected for all units in a population (i.e., population units), data are collected on a subset of the population units. This subset is called a sample. In the design-based approach, inferences about the underlying population are informed via a probabilistic process assigning some population units to be part of the sample. Alternatively, in the model-based approach, inferences are made from specific assumptions about the underlying process generating the data. Each paradigm has a deep historical context [@sterba2009alternative] and its own set of benefits and drawbacks [@hansen1983evaluation].

<!-- Shift focus to spatial data -->

Though the design-based and model-based approaches apply to statistical inference in a broad sense, we focus on comparing these approaches for spatial data. We define spatial data as data that incorporates the specific locations of the population units into either the design or estimation process. @de1990model give an early comparison of design-based and model-based approaches for spatial data, quashing the belief that design-based approaches could not be used for spatially correlated data. Since then, there have been several general comparisons between design-based and model-based approaches for spatial data [@brus1997random; @verhoef2002sampling; @verhoef2008spatial; @wang2012review; @brus2021statistical]. @cooper2006sampling reviews the two approaches in an ecological context before introducing a "model-assisted" variance estimator that combines aspects from each approach. In addition to @cooper2006sampling, there has been substantial research and development into estimators that use both design and model-based principles (see e.g., @sterba2009alternative, @cicchitelli2012model, @chan2020bayesian for a Bayesian approach).

<!-- Paragraph about the contribution of the manuscript and outlining the rest -->
Certainly comparisons between design-based and model-based approaches to spatial data have been studied. But no numerical comparison has been made between design-based approaches incorporating spatial information and design-based approaches. In this manuscript, we compare design-based approaches incorporating spatial information to model-based approaches for spatial data. We focus on finite populations, but these comparisons generalize to infinite populations as well. A finite population contains a finite number of population units; an example is lakes (treated as a whole with the lake centroid representing location) in the contiguous United States. An infinite population contains an infinite number of population units; an example is locations within a single lake. 

The rest of the manuscript is organized as follows. In Section \ref{sec:background}, we introduce and provide relevant background for the design-based and model-based approaches to finite population spatial data. In Section \ref{sec:numstudy}, we use a simulation study to compare the performance of the approaches in a variety of scenarios. In Section \ref{application}, we compare the performance of the approaches on real data that contains mercury concentration in lakes from the contiguous United States. And in Section \ref{sec:discussion}, we end with a discussion and provide directions for future research. 

# Background {#sec:background}

The design-based and model-based approaches incorporate randomness in fundamentally different ways. In this section, we describe the role of randomness and its effects on subsequent inferences. We then discuss specific inference methods of the approaches for spatial data. 

## Comparing Design-Based and Model-Based Approaches {#subsec:dvm_compare}

The design-based approach assumes the population is fixed. Randomness is incorporated via the selection of units in a smapling frame according to a sampling design. A sampling frame is the set of all units available to be sampled. A sampling design assigns a positive probability of inclusion (inclusion probability) to each unit in the sampling frame. Some examples of commonly used sampling designs include simple random sampling, stratified random sampling, and cluster sampling. If a sampling design selects units from the sampling frame while ignoring their spatial locations, we call them "Independent Random Sampling" (IRS) designs. If a sampling design selects units from the sampling frame while incorporating their spatial locations, we call them spatially balanced designs. Spatially balanced designs can be obtained using the Generalized Random Tessellation Stratified (GRTS) algorithm [@stevens2004spatially], which we discuss in more detail in Section \ref{subsec:spb_design}. The design-based approach combines the randomness of the sampling design and the data collected via the sample to estimate fixed, unknown parameters (e.g., means and totals) of a population.

Treating the data as fixed and incorporating randomness through the sampling design yields estimators having very few other assumptions. Confidence intervals for these types of estimators are typically derived using limiting arguments that incorporate all possible randomizations of sampling units selected via the sampling design. Means and totals, for example, are asymptotically normally distributed (normal) by the Central Limit Theorem (under some assumptions). If we repeatedly sample the surface, then 95% of all 95% confidence intervals constructed from a procedure with appropriate coverage will contain the true, fixed mean. @sarndal2003model and @lohr2009sampling provide thorough reviews of the design-based approach.

The model-based approach assumes the data are a random realization of a data-generating stochastic process. Randomness is incorporated through distributional assumptions on this process. Strictly speaking, randomness need not be incorporated through random sampling, though @diggle2010geostatistical warn against preferential sampling. Preferential sampling occurs when the process generating the data locations and the process being modeled are not independent of one another. To guard against preferential sampling, model-based approaches often still implement random sampling. 

Instead of estimating fixed but unknown parameters like a mean or total (as in the design-based approach), the goal of model-based inference in the spatial context is often to predict a realized variable, or value. For example, suppose the realized mean of all population units is the value of interest. Instead of \emph{estimating} a fixed, unknown mean, we are \emph{predicting} the value of the mean, a random variable. Prediction intervals are then derived using assumptions of the data generating process. If we repeatedly generate the response values from the same spatial process and sample, then 95% of all 95% prediction intervals constructed from a procedure with appropriate coverage will contain their respective realized means. @cressie1993statistics and @schabenberger2017statistical provide reviews of model-based approaches for spatial data. A visual comparison of the design-based and model-based assumptions is provided in Figure \ref{fig:fig1} (@verhoef2002sampling and @brus2021statistical provide similar figures).

```{r fig1, out.width = "100%", fig.cap = "A comparison of sampling under the design-based and model-based frameworks. Points circled are those that are sampled. In the top row, we have one fixed population, and three random samples of size four. The response values at each site are fixed, but we obtain different estimates for the mean response because the randomly sampled sites vary from sample to sample. In the bottom row, we have three realizations of the same spatial process sampled at the same locations. The spatial process generating the response values has a single mean, but the realized mean is different in each of the three panels."}
set.seed(10102021)

source(here("R", "sim_pop.R"))
N <- 9
pop_df <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                  psill = 0.9, range = 1, nugget = 0.1)

n <- 4
samp_df <- pop_df %>% sample_n(n) 
samp_df2 <- pop_df %>% sample_n(n) 
samp_df3 <- pop_df %>% sample_n(n) 


library(cowplot)
d1 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df, size = 5.5, shape = 1, 
             show.legend = FALSE, stroke = 1.5) +
  theme_bw() +
  labs(title = "Design 1",
       colour = "Response") +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        legend.position = "none",
        panel.grid.major = element_blank()) +
  xlim(-0.1, 1.1) +
  ylim(-0.1, 1.1)

d2 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df2, size = 5.5, shape = 1, show.legend = FALSE,
             stroke = 1.5) +
  theme_bw() +
  labs(title = "Design 2",
       colour = "Response") +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        legend.position = "none",
        panel.grid.major = element_blank()) +
  xlim(-0.1, 1.1) +
  ylim(-0.1, 1.1)

d3 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df3, size = 5.5, shape = 1, show.legend = FALSE,
             stroke = 1.5) +
  theme_bw() +
  labs(title = "Design 3",
       colour = "Response") +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(), 
        legend.position = "none",
        panel.grid.major = element_blank()) +
  xlim(-0.1, 1.1) +
  ylim(-0.1, 1.1)

pop_df_mod <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                      psill = 0.9, range = 1, nugget = 0.1)
pop_df_mod2 <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                       psill = 0.9, range = 1, nugget = 0.1)
pop_df_mod3 <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                      psill = 0.9, range = 1, nugget = 0.1)

indeces <- sample(1:N, size = n, replace = FALSE)
samp_df_mod <- pop_df_mod %>% slice(indeces)
samp_df_mod2 <- pop_df_mod2 %>% slice(indeces)
samp_df_mod3 <- pop_df_mod3 %>% slice(indeces)

m1 <- ggplot(data = pop_df_mod, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_bw() +
  labs(title = "Model 1",
       colour = "Response") +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(), 
        legend.position = "none",
        panel.grid.major = element_blank()) +
  xlim(-0.1, 1.1) +
  ylim(-0.1, 1.1)

m2 <- ggplot(data = pop_df_mod2, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod2, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_bw() +
  labs(title = "Model 2",
       colour = "Response") +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(), 
        legend.position = "none",
        panel.grid.major = element_blank()) +
  xlim(-0.1, 1.1) +
  ylim(-0.1, 1.1)

m3 <- ggplot(data = pop_df_mod3, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod2, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_bw() +
  labs(title = "Model 3",
       colour = "Response") +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(), 
        legend.position = "none",
        panel.grid.major = element_blank()) +
  xlim(-0.1, 1.1) +
  ylim(-0.1, 1.1)

library(ggpubr)
ggarrange(d1, d2, d3, m1, m2, m3, nrow = 2, ncol = 3,
          common.legend = TRUE, legend = "right")
```

## Spatially Balanced Design and Analysis {#subsec:spb_design}

The design-based approach can be used to select samples that are "well-spread" in space, or spatially balanced. Spatially balanced samples are useful because parameter estimates from these samples tend to vary less than parameter estimates from samples that are not spatially balanced [@stevens2004spatially; @barabesi2011sampling; @grafstrom2013well; @robertson2013bas; @wang2013design; @benedetti2017spatiallyreview]. The first spatially balanced sampling algorithm that saw widespread use was the Generalized Random Tessellation Stratified (GRTS) algorithm [@stevens2004spatially]. To quantify the spatial balance of a sample, @stevens2004spatially proposed loss metrics based on Voroni polygons. After the GRTS algorithm was developed, several other spatially balanced sampling algorithms have emerged, including the Local Pivotal Method [@grafstrom2012spatially; @grafstrom2018spatially], Spatially Correlated Poisson Sampling [@grafstrom2012spatiallypoisson], Balanced Acceptance Sampling [@robertson2013bas], Within-Sample-Distance Sampling [@benedetti2017spatially], and Halton Iterative Partitioning Sampling [@robertson2018halton]. In this manuscript, we use the Generalized Random Tessellation Stratified (GRTS) algorithm to select spatially balanced samples sampling because the algorithm has several attractive properties. It accommodates finite and infinite sampling frames, equal, unequal, and proportional (to size) inclusion probabilities, legacy (historical) sampling [@foster2017spatially], a minimum distance between units in a sample, and replacement units in a sample (which are units that can be sampled in place of an original unit that can no longer be sampled).
The GRTS algorithm samples from finite and infinite populations by utilizing a mapping between two-dimensional and one-dimensional space. The units in the two-dimensional sampling frame are divided into cells using a hierarchical address. This hierarchical address is then used to map the units from two-dimensional space to a one-dimensional line where each unit's line length equals its inclusion probability. A systematic sample is conducted on the line and linked back to a unit in two-dimensional space, which results in the desired sample. @stevens2004spatially provides further details. 

<!-- This makes it seem like HT is being used to estimate population parameters in GRTS? Needs to be in there, but maybe a sentence making it clear that this isn't being used? Or just change the order and talk about Local variance first and then mention these for more general settings? -->

After selecting a spatially balanced sample using the GRTS algorithm (i.e., a GRTS sample), data are collected and used to estimate population parameters. To unbiasedly estimate population means and totals from sample data, one can use the Horvitz-Thompson estimator [@horvitz1952generalization]. If $\tau$ is a population total, the Horvitz-Thompson estimate of $\tau$, denoted by $\hat{\tau}_{ht}$, is is given by
\begin{align}\label{eq:ht}
  \hat{\tau}_{ht} = \sum_{i = 1}^n Z_i \pi_i^{-1},
\end{align}
where $Z_i$ is the value of the $i$th unit in the sample and $\pi_i$ is the inclusion probability of the $i$th unit in the sample. An estimate of the population mean can be obtained by dividing $\hat{\tau}_{ht}$ by the number of population units, $N$. 

While the Horvitz-Thompson estimator is unbiased for population means and totals, it is also important to quantify the uncertainty in these estimates. @horvitz1952generalization and @sen1953estimate provide variance estimators for $\hat{\tau}_{ht}$, but these estimators have two drawbacks. First, they rely on calculating $\pi_{ij}$, the probability that unit $i$ and unit $j$ are both in the sample -- this quantity can be challenging if not impossible to calculate analytically. Second, these estimators ignore the spatial locations of the units in the sampling frame. To address these two drawbacks simultaneously, @stevens2003variance proposed the local neighborhood variance estimator. The local neighborhood variance estimator does not rely on $\pi_{ij}$ and incorporates spatial locations -- for technical details see @stevens2003variance. @stevens2003variance show the local neighborhood variance estimator tends to reduce the estimated variance of $\hat{\tau}$ compared to variance estimators ignoring spatial locations, yielding narrower confidence intervals for $\tau$.

## Finite Population Block Kriging

Finite Population Block Kriging (FPBK) is a model-based approach that expands the geostatistical Kriging framework to the finite population setting [@verhoef2008spatial]. Instead of developing inference based on a specific sampling design, we assume the data are generated by a spatial process. @verhoef2008spatial gives details on the theory of FPBK, but some of the basic principles are summarized below. Let ${\mathbf{z} \equiv \{\text{z}(s_1), \text{z}(s_2), . . . , \text{z}(s_N) \}}$ be an $N \times 1$ response vector at locations $s_1$, $s_2$, . . . , $s_N$ that can be measured at the $N$ population units. Suppose we want to predict some linear function of the response variable, $f(\mathbf{z}) = \mathbf{b}^\prime \mathbf{z}$, where $\mathbf{b}^\prime$ is a $1 \times N$ vector of weights. For example, if we want to predict the population total across all population units, then we would use a vector of 1's for the weights. 

We often only have a sample of the $N$ population units. Denoting quantities that are part of the sampled population units with a subscript \emph{s} and quantities that are part of the unsampled population units with subscript \emph{u}, let

\begin{equation}
\begin{pmatrix} \label{equation:Zmarginal}
    \mathbf{z}_s      \\
    \mathbf{z}_u
\end{pmatrix}
=
\begin{pmatrix}
  \mathbf{X}_s    \\
  \mathbf{X}_u
\end{pmatrix}
\bm{\beta} +
\begin{pmatrix}
\bm{\delta}_s    \\
\bm{\delta}_u
\end{pmatrix},
\end{equation}
where $\mathbf{X}_s$ and $\mathbf{X}_u$ are the design matrices for the sampled and unsampled population units, respectively, and $\bm{\beta}$ is the parameter vector of fixed effects.

Let $\bm{\delta} \equiv [\bm{\delta}_s \,\, \bm{\delta}_u]'$, where $\bm{\delta}_s$ and $\bm{\delta}_u$ are random errors for the sampled and unsampled population units, respectively. We assume $E(\bm{\delta}) = \mathbf{0}$ and that there is spatial correlation in $\bm{\delta}$ that can be modeled using a covariance function. It is common to assume the covariance function is second-order stationary and isotropic [@cressie1993statistics], and that the spatial covariance decreases as the separation between population units increases. Many spatial covariance functions exist, but the primary function we use throughout the simulations and applications in this manuscript is the exponential covariance function: the $i,j$th elment of the matrix $\cov(\bm{\delta})$ is
\mbox{}
\begin{align}\label{equation:expcov}
\cov(\delta_i, \delta_j) = 
\begin{cases} 
\sigma^2_{1}\exp(-h_{i,j}/\phi) & h_{i,j} > 0 \\
\sigma^2_{1} + \sigma^2_2 & h_{i,j} = 0
\end{cases}
,
\end{align}
where $\sigma^2_{1}$ is dependent random error variance measuring coarse-scale (correlated) variability, $\sigma^2_{2}$ is the independent random error variance measuring fine-scale (independent) variability, $\phi$ is the range parameter measuring the distance-decay rate of the correlation, and $h_{i,j}$ is the Euclidean distance between population units $i$ and $j$. Often $\sigma^2_{1}$ and $\sigma^2_{2}$ are called the partial sill and nugget, respectively. Any spatial covariance function could be used in the place of the exponential, including functions that allow for non-stationarity or anisotropy [@chiles1999geostatistics, pp. 80-93].

With the above model formulation, the Best Linear Unbiased Predictor (BLUP) for $f(\mathbf{b}'\mathbf{z})$ and its prediction variance can be computed. While details of the derivation are in @verhoef2008spatial, we note here that the predictor and its variance are both moment-based, meaning that they do not rely on any distributional assumptions.

We note that we only use FPBK in this paper in order to focus more on comparing the design-based and model-based approaches. Other methods, such as k-nearest-neighbors [@fix1989discriminatory; @ver2013comparison], random forest [@breiman2001random], Bayesian models [@chan2020bayesian], among others, could also be used to obtain predictions for a mean or total from spatially correlated responses of a finite population. We choose to use FPBK because it is faster than a Bayesian approach and it was developed with theoretically-based variance estimators of means and totals for spatial data, whereas random forests and k-nearest-neighbors use ad-hoc variance estimators in most cases [@ver2013comparison]; additionally, FBPK outperformed the other methods in most scenarios. 

# Numerical Study {#sec:numstudy}

We used a simulation study to investigate performance of four sampling-analysis combinations: IRS-Design, IRS with a design-based analysis; IRS-Model, IRS with a model-based analysis; GRTS-Design, GRTS sampling with a design-based analysis; and GRTS-Model, GRTS sampling with a model-based analysis. These combinations are also provided in Table \ref{tab:designanalysis}.

```{r, echo = FALSE, results = "asis"}
tab <- matrix(c("IRS-Design", "IRS-Model", "GRTS-Design", "GRTS-Model"),
       nrow = 2, byrow = TRUE) %>%
  as.table()
row.names(tab) <- c("IRS", "GRTS")
xtab1 <- xtable(tab, col.names = c("Design", "Model"), caption = "\\label{tab:designanalysis} Sampling-analysis combinations in the simulation study. The rows give the two types of sampling designs and the columns give the two types of analyses.")
align(xtab1) <- "r|ll"
names(xtab1) <- c("Design", "Model")
print(xtab1, comment = FALSE)
## I really want "Analysis" to appear as a row header and "Sampling Design" 
## to appear as a column header, but this isn't easy to figure out.
## I couldn't figure this out with xtable either so it might need to be
## made "by hand."
```

Performance of the four sampling-analysis combinations was evaluated in 36 different simulation scenarios. The 36 scenarios resulted from the crossing of three sample sizes, two location layouts, two response types, and three proportions of dependent random error. The three sample sizes ($n$) were $n = 50, n = 100,$ and $n = 200$. Samples were always selected from a population size ($N$) of $N = 900$. The two location layouts were random and gridded. Locations in the random layout were selected randomly from the unit square ($[0, 1] \times [0, 1]$). Locations in the gridded layout were selected randomly on a fixed grid from the unit square. The two response types were normal and lognormal. For the normal response type, the response was simulated using mean-zero random errors with the exponential covariance (Equation$~$\ref{equation:expcov}) for varying proportions of dependent random error. The proportion of dependent random error is represented by $\sigma^2_1 / (\sigma^2_1 + \sigma^2_2)$, where $\sigma^2_1$ and $\sigma^2_2$ are from Equation$~$\ref{equation:expcov}. The total variance, $\sigma^2_1 + \sigma^2_2$, was always 2. The range was always $\sqrt{2} / 3$, which means that the correlation in the dependent random error decayed to nearly zero at the largest possible distance between two units in the domain. For the lognormal response type, the response was first simulated using the same approach as for the normal response type, except that the total variance was 0.6931 instead of 2. The response was then exponentiated, yielding a random variable whose total variance is 2. The lognormal responses were used to evaluate performance of the sampling-analysis approaches for data that were skewed.

```{r, echo = FALSE, results = "asis"}
n <- c("50", "100", "200")
site_locations <- c("Random", "Gridded", "")
psill_ratio <- c("0", "0.5", "0.9")
resp_type <- c("Normal", "Lognormal", "")
parm_tab <- rbind(n, site_locations, psill_ratio, resp_type)
parm_tab[c(2, 4), 3] <- "-"
row.names(parm_tab) <- c("Sample Size (n)", "Location Layout", 
                         "Proportion of Dependent Error", "Response Type")
# parm_tab <- parm_tab[c(1, 2, 4, 3), ]
parm_xtab <- xtable(parm_tab, caption = "\\label{tab:parmtab} Simulation scenario options. All combinations of sample size, location layout, response type, and proportion of dependent random error composed the 36 simulation scenarios. In each simualtion scenario, the total variance was two.")
align(parm_xtab) <- "r|lll"
print(parm_xtab, include.colnames = FALSE, hline.after = c(0, nrow(parm_xtab)), comment = FALSE)
```

In each of the 36 simulation scenarios, there were 2000 independent simulation trials. In each trial, IRS and GRTS samples were selected and then design-based and model-based analyses were used to estimate the mean and construct confidence (design-based) or prediction (model-based) intervals. We recorded the bias, squared error, and interval coverage for all sampling-analysis combinations in each trial. Then we summarized the performance of the combinations across trials by calculating average bias, rMS(P)E (root-mean-squared error for the design-based approaches and root-mean-squared-prediction error for the model-based approaches), and the rate at which the true mean is contained in its 95% interval. The GRTS algorithm and the local neighborhood variance estimator are available in the \textbf{\textsf{R}} package `spsurvey` [@dumelle2021spsurvey]. FPBK is available in the `sptotal` \textbf{\textsf{R}} package [@higham2021sptotal] and covariance parameters were estimated using Restricted Maximum Likelihood  [@patterson1971recovery; @harville1977maximum; @wolfinger1994computing].

The average bias was nearly zero for all four combinations in all 36 scenarios, so we omit a more detailed summary of those results here. Tables for average bias in all 36 simulation scenarios are provided in the supplementary material.

Figure \ref{fig:figeff} shows the relative rMS(P)E of the four approaches from Table \ref{tab:designanalysis} using the random location layout with "IRS-Design" as the baseline. More formally, the relative rMS(P)E is defined as
\begin{equation*}
\frac{\text{rMS(P)E of sampling-analysis combination}}{\text{rMS(P)E of IRS-Design}},
\end{equation*}
When there is no spatial correlation (Figure \ref{fig:figeff}, top row), the four sampling-analysis combinations have approximately equal rMS(P)E. So, using GRTS or using a spatial model does not result in much, if any, loss in efficiency even when the response variable is not spatially correlated. When there is spatial correlation (Figure \ref{fig:figeff}, middle and bottom row), the GRTS-Model combination tends to perform best, followed by GRTS-Design, IRS-Model, and finally IRS-Design, though the difference in relative rMS(P)E among IRS-Model, GRTS-Design, and GRTS-Model is relatively small.  As the strength of spatial correlation increases, the gap in rMS(P)E between IRS-Design and the other combinations widens. Finally we note that when there is spatial correlation, IRS-Model outperforms IRS-Design by a large margin, suggesting that the poor design properties of IRS are largely mitigated by the model-based analysis. These conclusions are similar to those observed in the grid location layout. Tables for rMS(P)E in all 36 simulation scenarios are provided in the supplementary material.

```{r figeff, out.width = "100%", fig.cap = "Relative rMS(P)E for the four sampling-analysis combinations. The rows indicate the proportion of dependent error and the columns indicate the response type.", message = FALSE, warning = FALSE}
library(tidyverse)
library(here)

files <- list.files(path = here("inst", "output", "simulation_summary"), pattern = "*.csv", full.names = TRUE)

combo_data <- purrr::map_df(files,
                            ~read_csv(.x) %>% mutate(filename = .x))

combo_data <- combo_data %>%
  dplyr::filter(gridded == FALSE) %>%
  mutate(sim = interaction(n, psill, resptype)) %>% ## , gridded
  mutate(approach = fct_relevel(approach, c("Design IRS", "Model IRS",
                                            "Design GRTS", "Model GRTS"))) %>%
  mutate(resptype = fct_relevel(resptype, c("normal", "lognormal")))
combo_data <- combo_data %>% group_by(sim) %>% mutate(designirsrmspe = if_else(approach == "Design IRS", true = rmspe, false = NA_real_)) %>%
  fill(designirsrmspe, .direction = "downup") %>%
  mutate(rel_efficiency = rmspe / designirsrmspe) %>%
  ungroup() %>%
  mutate(psill_ratio = 1 - nugget_ratio) %>%
  mutate(n_factor = factor(n))

colour_scale <- c("goldenrod1", "goldenrod4", "mediumpurple1", "mediumpurple4")
resptype_labs <- c(normal = "Response: Normal", lognormal = "Response: Lognormal")
psill_ratio_labs <- c("0" = "Prop DE: 0", "0.5" = "Prop DE: 0.5", "0.9" = "Prop DE: 0.9")
effplot <- ggplot(data = combo_data, aes(x = n_factor, y = rel_efficiency,
                              colour = approach)) +
  facet_grid(
    psill_ratio ~ resptype,
    labeller = labeller(resptype = resptype_labs, psill_ratio = psill_ratio_labs)
  ) +
  geom_jitter(width = 0.24, size = 2.5) +
  scale_colour_manual(values = colour_scale) +
  theme_bw(base_size = 14) +
  labs(x = "Sample Size", colour = "Approach",
       y = "Relative Efficiency")
effplot
```

We also studied 95% interval coverage among the combinations. The design-based 95% confidence intervals and model-based 95% prediction intervals were constructed using the normal distribution. Justification for the design-based and model-based intervals comes from the asymptotic normality of totals via the Central Limit Theorem.  

Figure \ref{fig:figconf} shows the 95% interval coverage for each of the four combinations in the random location layout. All four combinations have fairly similar interval coverage within each scenario. Coverage in the normal response scenarios tended to be near 95% and slightly higher than coverage in the lognormal scenarios. Coverage in the lognormal scenarios still generally exceeded 90%. Coverage tended to always increase with the sample size. At a sample size of 200, all four combinations had approximately 95% interval coverage in both response scenarios and all dependent error proportions.  These conclusions were similar to those found in the grid location layout.
Tables for interval coverage in all 36 simulation scenarios are provided in the supplementary material.


```{r figconf, out.width = "100%", fig.cap = "Interval coverage for the four sampling-analysis combinations. The rows indicate the proportion of dependent error and the columns indicate the response type. The solid, black line in each plot represents 95\\% coverage.", message = FALSE, warning = FALSE}
ggplot(data = combo_data, aes(x = n_factor, y = coverage, colour = approach)) +
  geom_hline(yintercept = 0.95) +
  geom_jitter(width = 0.24, size = 2.5) + 
  facet_grid(
    psill_ratio ~ resptype,
    labeller = labeller(resptype = resptype_labs, psill_ratio = psill_ratio_labs)
  ) +
  scale_colour_manual(values = colour_scale) +
  ylim(0.80, 1) +
  theme_bw(base_size = 14) +
  labs(x = "Sample Size", colour = "Approach",
       y = "Interval Coverage")
```

# Application {#application}

The Environmental Protection Agency (EPA), states, and tribes periodically conduct National Aquatic Research Surveys (NARS) in the United States to assess the water quality of various bodies of water. We will use the 2012 National Lakes Assessment (NLA), which measures various aspects of lake health and water quality in lakes in the contiguous United States, to study mercury concentration. Although we know the true mean mercury concentration values for the 986 lakes from the 2012 NLA, we will explore whether or not we obtain an adequately precise estimate for the realized mean mercury concentration if we sample only 100 of the 986 lakes.

```{r, message = FALSE, warning = FALSE, echo = FALSE, results = "hide"}
library(tidyverse)
library(here)
library(DvMsp)
data(nla_df) # may need to reinstall package
nla_df
factor(nla_df$TOTALHG_UNITS) ## all same units

nla_df %>% group_by(SITE_ID) %>%
  summarise(nonmiss = sum(!is.na(TOTALHG_RESULT))) %>%
  ungroup() %>% summarise(maxnonmiss = max(nonmiss))
## HG never measured twice at the same site.

nla_df %>% group_by(SITE_ID) %>%
  summarise(nonmiss = sum(!is.na(TOTALHG_RESULT))) %>%
  summarise(sumnomiss = sum(nonmiss == 0))
## 35 sites never have HG measured. These will be dropped as well as the duplicate sites.

## in duplicate sites, fill in the value for RDis_IX
nla_nomiss <- nla_df %>%
  group_by(SITE_ID) %>%
  fill(RDis_IX, .direction = "downup") %>%
  ungroup() %>%
  filter(!is.na(TOTALHG_RESULT)) %>%
  rename(total_hg = "TOTALHG_RESULT")

nla_nomiss_both <- nla_nomiss
## check
nla_nomiss_both %>% group_by(SITE_ID) %>% count() %>%
  ungroup() %>%
  summarise(not1 = sum(n != 1))

## transform coordinates
library(sptotal)
coord_list <- LLtoTM(cm = mean(nla_nomiss_both$INDEX_LON_DD),
                     lat = nla_nomiss_both$INDEX_LAT_DD, 
                     lon = nla_nomiss_both$INDEX_LON_DD)
nla_nomiss_both$xcoords <- coord_list$xy[ ,1]
nla_nomiss_both$ycoords <- coord_list$xy[ ,2]
```

```{r, echo = FALSE}
mean_hg <- mean(nla_nomiss_both$total_hg)
# mean(nla_nomiss_both$RDis_IX)
```

Figure \ref{fig:figdata} shows that mercury concentration is right-skewed, with most lakes having a low value of mercury concentration but a few having a much higher concentration. Mercury concentration exhibits some spatial correlation, with high mercury concentrations in lakes in the northeast and north central United States. The realized mean mercury concentration in the 986 lakes is 103.2 ng / g.

```{r, results = "hide", fig.keep = "none"}
## IRS Sample, Model Analysis

set.seed(080421)
n <- 100
lakesobs <- nla_nomiss_both %>% sample_n(n) 
lakesunobs <- anti_join(nla_nomiss_both, lakesobs)
lakesunobs$total_hg <- NA

lakes_test <- bind_rows(lakesobs, lakesunobs) 
lakes_test$wts <- 1 / nrow(lakes_test) ## predicting for mean

slmfitout_exp_lakes <- slmfit(formula = total_hg ~ 1,
                              data = lakes_test, 
                              xcoordcol = 'xcoords',
                              ycoordcol = 'ycoords',
                              CorModel = "Exponential")
summary(slmfitout_exp_lakes)
plot(slmfitout_exp_lakes)

pred_exp_lakes <- predict(slmfitout_exp_lakes, wtscol = "wts",
                          conf_level = 0.95)
print(pred_exp_lakes)
mean_irs_mod <- pred_exp_lakes$FPBK_Prediction
se_irs_mod <- sqrt(pred_exp_lakes$PredVar)
lb_irs_mod <- pred_exp_lakes$conf_bounds[1]
ub_irs_mod <- pred_exp_lakes$conf_bounds[2]

realized_mean <- mean(nla_nomiss_both$total_hg) ## compute realized mean
```

```{r, results = "hide"}
## IRS Sample, Design Analysis
## 
irs_info <- lakesobs %>% summarise(meandoc = mean(total_hg),
                                   vardoc = var(total_hg))
N <- nrow(nla_nomiss_both); n <- nrow(lakesobs)
irs_se_irs_samp <- sqrt((irs_info$vardoc / n) * (N - n) / N)
irs_lb_irs_samp <- irs_info$meandoc - 1.96 * irs_se_irs_samp
irs_ub_irs_samp <- irs_info$meandoc + 1.96 * irs_se_irs_samp
irs_info$meandoc; sqrt(irs_info$vardoc)
irs_lb_irs_samp; irs_ub_irs_samp
```

```{r, results = "hide"}
## GRTS Sample, Design Analysis
data_sf <- sf::st_as_sf(nla_nomiss_both, coords = c("xcoords", "ycoords"),
                        crs = 5070)
library(spsurvey)
grts_samp <- grts(data_sf, n_base = n)
grts_bind <- sp_rbind(grts_samp) 

## get coordinates
grts_coords <- sf::st_coordinates(grts_bind)
## make data frame
grts_df <- data.frame(
  response = grts_bind$total_hg,
  x = grts_coords[, "X"],
  y = grts_coords[, "Y"],
  siteID = grts_bind$siteID,
  wgt = grts_bind$wgt
)
## head(grts_df)
summary(grts_df$response)

design_analysis <- cont_analysis(
  grts_df,
  siteID = "siteID",
  vars = "response",
  weight = "wgt",
  xcoord = "x",
  ycoord = "y"
)
## just return the mean info
## design_mean <- subset(design_analysis$Pct, Statistic == "Mean")
design_mean_grts <- design_analysis$Mean
design_mean_grts$Estimate
design_mean_grts$StdError
design_mean_grts$LCB95Pct
design_mean_grts$UCB95Pct
```

```{r, results = "hide"}
## GRTS Sample, Model Analysis

grts_coords_resp <- grts_df %>% select(-siteID, -wgt) %>%
  rename(total_hg = "response", xcoords = "x", ycoords = "y")
grts_unsamp <- anti_join(nla_nomiss_both, grts_coords_resp)
grts_unsamp$total_hg <- NA
grts_unsamp <- grts_unsamp %>% select(total_hg, xcoords, ycoords)
grts_full <- dplyr::bind_rows(grts_coords_resp, grts_unsamp)

grts_full$wts <- 1 / nrow(grts_full)
mod_grts <- slmfit(total_hg ~ 1, data = grts_full,
                   xcoordcol = "xcoords",
                   ycoordcol = "ycoords")
pred_mod_grts <- predict(mod_grts, wtscol = "wts")
model_mean_grts <- pred_mod_grts$FPBK_Prediction
model_se_grts <- sqrt(pred_mod_grts$PredVar)
model_lb_grts <- model_mean_grts + -1 * 1.96 * model_se_grts
model_ub_grts <- model_mean_grts + 1 * 1.96 * model_se_grts
model_mean_grts
model_se_grts
model_lb_grts
model_ub_grts
```

```{r, results = "hide"}
## combine results
res_df <- tibble(approach = c("IRS-Design", "GRTS-Design", "IRS-Model", "GRTS-Model"),
       realized_mean = c(realized_mean, realized_mean, realized_mean,
                     realized_mean),
       estimate = c(irs_info$meandoc,
                    design_mean_grts$Estimate, as.vector(mean_irs_mod),
                    as.vector(model_mean_grts)),
       se = c(irs_se_irs_samp, design_mean_grts$StdError, as.vector(se_irs_mod),
              as.vector(model_se_grts)),
       lb = c(irs_lb_irs_samp, design_mean_grts$LCB95Pct, as.vector(lb_irs_mod),
              as.vector(model_lb_grts)),
       ub = c(irs_ub_irs_samp, design_mean_grts$UCB95Pct, as.vector(ub_irs_mod),
              as.vector(model_ub_grts)))
res_df <- res_df %>% slice(1, 3, 2, 4)
```

```{r figdata, out.width = "49%", fig.cap = "Population distribution of mercury concentration (hg) for 986 lakes in the contiguous United States in a spatial layout (left) and a histogram (right).", message = FALSE, warning = FALSE, fig.show='hold', fig.align='center'}
merc <- ggplot(data = nla_nomiss_both, aes(x = total_hg)) +
  geom_histogram(colour = "black", fill = "white", bins = 15) +
  labs(x = "HG (ng / g)")
# dist <- ggplot(data = nla_nomiss_both, aes(x = RDis_IX)) +
#   geom_histogram(colour = "black", fill = "white", bins = 15) +
#   labs(x = "Lakeshore Disturbance")
merc_map <- ggplot(data = nla_nomiss_both, aes(x = xcoords, y = ycoords)) +
  geom_point(aes(colour = total_hg)) +
  scale_colour_viridis_c() +
  labs(x = "", y = "", colour = "Hg") +
  lims(x = c(0, 6500)) +
  coord_quickmap() +
  theme_bw(base_size = 20) + 
  theme(axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
      legend.position = c(0.85, 0.5),
      legend.key.size = unit(0.75, "cm"))

merc_hist <- ggplot(data = nla_nomiss_both, aes(x = total_hg)) +
  geom_histogram(bins = 50) + 
  labs(x = "Hg", y = "Count") +
  theme_bw(base_size = 20)

merc_map
merc_hist
```

```{r apptab, results = "asis"}
res_df_drop <- res_df[ ,-2]
names(res_df_drop) <- c("Approach", "Estimate", "SE", "95% LB", "95% UB")
xtab_app <- xtable(res_df_drop, digits = 1, caption = "\\label{tab:appliedtab} Application of design-based and model-based approaches to the NLA data set on mercury concentration. The true mean concentration is 103.2 ng / g.")
print(xtab_app, include.rownames = FALSE, comment = FALSE)
```

We selected a single IRS sample and a single GRTS sample and estimated the mean mercury concentration and its standard error using using design-based and model-based approaches; Table \ref{tab:appliedtab} shows the results. For all four sampling-analysis combinations, the true realized mean mercury concentration is within the bounds of the 95% intervals. However, we should not generalize these results to any other data or even to other samples from these data. But, we do note a couple of patterns. The design-based IRS analysis shows the largest standard error: a likely reason is that this is the only approach that does not incorporate any spatial information regarding mercury concentration across the contiguous United States. We also see that both approaches using the GRTS sample have a lower standard error than the both approaches using the IRS sample. We would expect this to be the case for most samples because mercury concentration exhibits spatial patterning, so a spatially balanced sample should usually yield a lower standard error. 

To better understand the dependence structure in mercury concentration, the empirical semivariogram and corresponding fit of the model-based approaches can be visualized. The empirical semivariogram quantifies the halved squared differences (semivariance) among response values at different distances apart. If a process exhibits strong spatial dependence, the empirical semivariogram will have small values at small distances and large values at large distances. Figure \ref{fig:figsv} shows the empirical semivariogram for GRTS-Model, displaying the average semivariance for several distances.  Overlain onto Figure \ref{fig:figsv} is the estimated semivariance obtained using the covariance parmaeters from the REML fit of GRTS-Model. Figure \ref{fig:figsv} provides evidence that there is strong correlation in mercury concentration among the sites.

```{r figsv, out.width = "85%", fig.align='center', fig.cap = "The empirical semivariogram (black circles) of mercury concentration against the REML fit using the estimated covariance parameters (black line) from GRTS-Model."}
plot(mod_grts)
```


# Discussion {#sec:discussion}

The design-based and model-based approaches to inference are fundamentally different paradigms by which samples are selected and data are analyzed. The design-based approach incorporates randomness through sampling to estimate a population parameter. The model-based approach incorporates randomness through distributional assumptions to predict the realized values of a random process. Though these approaches have often been compared in the literature both from theoretical and analytical perspectives, our contribution lies in studying them in a spatial context while implementing spatially balanced sampling. Aside from the theoretical differences described, a few analytical findings from the simulation study are particularly notable. First, the sampling decision (GRTS vs IRS) is most important when using a design-based analysis. Though GRTS-Model still outperformed IRS-Model, the model-based analysis mitigated much of the inefficiency of the IRS sample. Second, independent of the analysis approach, there is no reason to use IRS over GRTS for sampling spatial data, as GRTS-Design and GRTS-Model generally performed at least as well as their IRS counterparts when there was no spatial correlation and noticeably better than there IRS counterparts when there was spatial correlation. Third, The stronger the spatial correlation, the larger the gap in rMS(P)E between IRS-Design and the other sampling-analysis combinations. Fourth and finally, interval coverage for the normal response was very close to 95% for all sample sizes, while interval coverage for the lognormal response was not very close to 95% until $n = 200$.

There are several benefits and drawbacks of the design-based and model-based approaches for spatial data, some of which we have not yet discussed but are worthy of consideration in future research.  Design-based approaches are often computationally efficient, while model-based estimation of covariance parameters can be computationally burdensome, especially for likelihood-based methods such as REML that rely on inverting a covariance matrix. The design-based approach also more naturally handles binary data, free from the more complicated logistic regression formulation commonly used to handle binary data in a model-based approach. The model-based approach, however, can more naturally quantify the relationship between covariates (predictor variables) and the response variable. The model-based approach also yields estimated spatial covariance parameters, which help better understand the process of study. Model selection is also possible using model-based approaches and criteria such as cross validation, likelihood ratio tests, or AIC [@akaike1974new]. Model-based approaches are capable of more efficient small-area estimation than design-based approaches by leveraging distributional assumptions in areas with few observed sites. Model-based approaches can also compute site-by-site predictions at unobserved locations and use them to construct informative visualizations. The benefits and drawbacks of both approaches, alongside our theoretical and analytical comparisons, should be seriously considered when choosing among them. This is especially true from an analysis perspective, as we found that using a spatially balanced sampling algorithm benefits both design-based and model-based analyses.

# Data and Code Availability {.unnumbered}

This manuscript has a supplementary R package that contains all of the data and code used. Instructions for download at available at [https://github.com/michaeldumelle/DvMsp](https://github.com/michaeldumelle/DvMsp).

# Supplementary Material {.unnumbered}

In the supplementary material, we provide tables presenting summary statistics for all 36 simulation scenarios.

# Acknowledgements {.unnumbered}

The views expressed in this manuscript are those of the authors and do not necessarily represent the views or policies of the U.S. Environmental Protection Agency. Any mention of trade names, products, or services does not imply an endorsement by the U.S. government or the U.S. Environmental Protection Agency. The U.S. Environmental Protection Agency does not endorse any commercial products, services, or enterprises.


# References {#references .unnumbered}

