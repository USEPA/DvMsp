---
title: A comparison of design-based and model-based approaches for finite population spatial data.
author:
  - name: Michael Dumelle
    affiliation: USEPA
    footnote: 1
  - name: Matt Higham
    affiliation: STLAW
  - name: Jay M. Ver Hoef
    affiliation: NOAA
  - name: Anthony R. Olsen
    affiliation: USEPA
  - name: Lisa Madsen
    affiliation: OSU
address:
  - code: USEPA
    address: United States Environmental Protection Agency, 200 SW 35th St, Corvallis, Oregon, 97333
  - code: STLAW
    address: Saint Lawrence University Department of Mathematics, Computer Science, and Statistics, 23 Romoda Drive, Canton, New York, 13617
  - code: NOAA
    address: Marine Mammal Laboratory, Alaska Fisheries Science Center, National Oceanic and Atmospheric Administration, Seattle, Washington, 98115
  - code: OSU
    address: Oregon State University Department of Statistics, 239 Weniger Hall, Corvallis, Oregon, 97331
footnote:
    code: 1
    text: "Corresponding Author: Michael Dumelle (Dumelle.Michael@epa.gov)"
abstract: |
  1. 
  2.
  3.
  4.
  The design-based and model-based approaches to frequentist statistical inference lie on fundamentally different foundations. In the design-based approach, inference depends on random sampling. In the model-based approach, inference depends on distributional assumptions. In this manuscript, we compare the approaches for finite population spatial data. We first provide relevant background for the approaches and then use a simulation study and an analysis of real mercury concentration data to numerically compare them. We find that sampling plans that incorporate spatial locations (spatially balanced samples) perform better than sampling plans ignoring spatial locations (non-spatially balanced samples), regardless of whether design-based or model-based approaches were used to analyze the data. We also find that within sampling plans, the model-based approaches often outperform design-based approaches, even for skewed data. This gap in performance is small when spatially balanced samples are used but large when non-spatially balanced samples are used.
journal: "Methods in Ecology and Evolution"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
linenumbers: true
numbersections: true
csl: elsevier-harvard.csl
preamble: >
  \usepackage{bm}
  \usepackage{bbm}
  \usepackage{color}
  \DeclareMathOperator{\var}{{var}}
  \DeclareMathOperator{\cov}{{cov}}
  \usepackage{caption}
  \usepackage{subcaption}
  \usepackage{setspace}
  \doublespacing
output: rticles::elsevier_article
---

# Keywords {.unnumbered}

Design-based inference; Finite Population Block Kriging (FPBK); Generalized Random Tessellation Stratified (GRTS) algorithm; Model-based inference; Spatially balanced sampling; Spatial covariance; 

# Introduction {#sec:introduction}

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  warning = FALSE, 
  message = FALSE,
  include = TRUE, 
  echo = FALSE
)
library(tidyverse)
library(here)
library(xtable) # latex tables
```

<!-- Brief introduction to model based and design based -->

There are two general approaches for using data to make frequentist statistical inferences about a population: design-based and model-based. When data cannot be collected for all units in a population (i.e., population units), data are collected on a subset of the population units. This subset is called a sample. In the design-based approach, inferences about the underlying population are informed via a probabilistic process assigning some population units to be part of the sample. Alternatively, in the model-based approach, inferences are made from specific assumptions about the underlying process generating the data. Each paradigm has a deep historical context [@sterba2009alternative] and its own set of benefits and drawbacks [@hansen1983evaluation].

<!-- Shift focus to spatial data -->

Though the design-based and model-based approaches apply to statistical inference in a broad sense, we focus on comparing these approaches for spatial data. We define spatial data as data that incorporates the specific locations of the population units into either the design or estimation process. @de1990model give an early comparison of design-based and model-based approaches for spatial data, quashing the belief that design-based approaches could not be used for spatially correlated data. Since then, there have been several general comparisons between design-based and model-based approaches for spatial data [@brus1997random; @verhoef2002sampling; @verhoef2008spatial; @wang2012review; @brus2021statistical]. @cooper2006sampling reviews the two approaches in an ecological context before introducing a "model-assisted" variance estimator that combines aspects from each approach. In addition to @cooper2006sampling, there has been substantial research and development into estimators that use both design and model-based principles (see e.g., @sterba2009alternative, @cicchitelli2012model, @chan2020bayesian for a Bayesian approach).

<!-- Paragraph about the contribution of the manuscript and outlining the rest -->
Certainly comparisons between design-based and model-based approaches to spatial data have been studied. But no numerical comparison has been made between design-based approaches incorporating spatial information and design-based approaches. In this manuscript, we compare design-based approaches incorporating spatial information to model-based approaches for spatial data. We focus on finite populations, but these comparisons generalize to infinite populations as well. A finite population contains a finite number of population units; an example is lakes (treated as a whole with the lake centroid representing location) in the contiguous United States. An infinite population contains an infinite number of population units; an example is locations within a single lake. 

The rest of the manuscript is organized as follows. In Section \ref{sec:background}, we introduce and provide relevant background for the design-based and model-based approaches to finite population spatial data. In Section \ref{sec:mm}, we describe how we compare performance of the approaches wiht a simulation study and an analysis of real data that contains mercury concentration in lakes from the contiguous United States. In Section \ref{sec:results}, we present results from the simulation study and the analysis of mercury concentrations. And in Section \ref{sec:discussion}, we end with a discussion and provide directions for future research. 

## Background {#sec:background}

The design-based and model-based approaches incorporate randomness in fundamentally different ways. In this section, we describe the role of randomness for each approach and the subsequent effects on statistical inferences for spatial data.

### Comparing Design-Based and Model-Based Approaches {#subsec:dvm_compare}

The design-based approach assumes the population is fixed. Randomness is incorporated via the selection of units in a sampling frame. A sampling frame is the set of all units available to be sampled. Units from the sampling frame are selected as part of the sample according to a sampling design, which assigns a positive probability of inclusion (inclusion probability) to each unit from the sampling frame. Some examples of commonly used sampling designs include simple random sampling, stratified random sampling, and cluster sampling. When sampling designs incorporate spatial locations into sampling, we call the resulting samples "spatially balanced." One approach to selecting spatially balanced samples is the Generalized Random Tessellation Stratified (GRTS) algorithm [@stevens2004spatially], which we discuss in more detail in Section \ref{subsec:spb_design}. When sampling designs do not incorporate spatial locations into sampling, we call the resulting samples "non-spatially balanced." 

Fundamentally, the design-based approach combines the randomness of the sampling design with the data collected via the sample to justify the estimation and uncertainty quantification of fixed, unknown parameters of a population (e.g., a population mean). Treating the data as fixed and incorporating randomness through the sampling design yields estimators having very few other assumptions. Confidence intervals for these types of estimators are typically derived using limiting arguments that incorporate all possible samples. Sample means, for example, are asymptotically normal (Gaussian) by the Central Limit Theorem (under some assumptions). If we repeatedly select samples from the population, then 95% of all 95% confidence intervals constructed from a procedure with appropriate coverage will contain the true, fixed mean. @sarndal2003model and @lohr2009sampling provide thorough reviews of the design-based approach.

The model-based approach assumes the data are a random realization of a data-generating stochastic process. Randomness is incorporated through distributional assumptions on this process. Strictly speaking, randomness need not be incorporated through random sampling, though @diggle2010geostatistical warn against preferential sampling. Preferential sampling occurs when the process generating the data locations and the process being modeled are not independent of one another. To guard against preferential sampling, model-based approaches often still implement some form of random sampling. 

Instead of estimating fixed, unknown population parameters, as in the design-based approach, often the goal of model-based inference is to predict a realized variable, or value. For example, suppose the realized mean of all population units is the value of interest. Instead of \emph{estimating} a fixed, unknown mean, we are \emph{predicting} the value of the mean, a random variable. Prediction intervals are then derived using assumptions of the data-generating stochastic process. If we repeatedly generate response values from the same data-generating stochastic process and select samples, then 95% of all 95% prediction intervals constructed from a procedure with appropriate coverage will contain their respective realized means. @cressie1993statistics and @schabenberger2017statistical provide thorough reviews of model-based approaches for spatial data. In Fig. \ref{fig:fig1}, we provide a visual comparison of the design-based and model-based approaches (@verhoef2002sampling and @brus2021statistical provide similar figures).

\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/dvm_comp.jpeg}
  \caption{A visual comparison of the design-based and model-based approaches. In the top row, there is one fixed population with nine population units and three random samples of size four (points circled are those sampled). The response values at each site are fixed, but we obtain different estimates for the mean response in each random sample. In the bottom row, there are three realizations of the same data-generating stochastic process that are all sampled at the same four locations. The data-generating stochastic process has a single mean, but the mean of the nine population units is different in each of the three realizations}
  \label{fig:fig1}
\end{figure}

### Spatially Balanced Design and Analysis {#subsec:spb_design}

We previously mentioned that the design-based approach can be used to select spatially balanced samples (samples that incorporate spatial locations of the population units and are "well-spread" is space). Spatially balanced samples are useful because parameter estimates from these samples tend to vary less than parameter estimates from samples that are not spatially balanced [@stevens2004spatially; @barabesi2011sampling; @grafstrom2013well; @robertson2013bas; @wang2013design; @benedetti2017spatiallyreview]. The first spatially balanced sampling algorithm seeing widespread use is the Generalized Random Tessellation Stratified (GRTS) algorithm [@stevens2004spatially]. To quantify the spatial balance of a sample, @stevens2004spatially proposed loss metrics based on Voronoi polygons (Dirichlet Tessellations). After the GRTS algorithm was developed, several other spatially balanced sampling algorithms emerged, such as the Local Pivotal Method [@grafstrom2012spatially; @grafstrom2018spatially], Spatially Correlated Poisson Sampling [@grafstrom2012spatiallypoisson], Balanced Acceptance Sampling [@robertson2013bas], Within-Sample-Distance Sampling [@benedetti2017spatially], and Halton Iterative Partitioning Sampling [@robertson2018halton]. In this manuscript, we select spatially balanced samples using the Generalized Random Tessellation Stratified (GRTS) algorithm because it has several attractive properties. More specifically, the GRTS algorithm accommodates finite and infinite sampling frames, equal, unequal, and proportional (to size) inclusion probabilities, legacy (historical) sampling [@foster2017spatially], a minimum distance between units in a sample, and replacement units (replacement units are population units that can be sampled when a population unit originally selected can no longer be sampled). The GRTS algorithm selects samples by utilizing a particular mapping between two-dimensional and one-dimensional space that preserves proximity relationships. Via this mapping, units in two-dimensional space are partitioned using a hierarchical address. This hierarchical address is used to map population units to a one-dimensional line. On the one dimensional line, each population unit's line length equals its inclusion probability. Then, a systematic sample of population units is selected on the line, yielding desired sample. @stevens2004spatially provides more technical details. 

After selecting a sample and collecting data, unbiased estimates of population means and totals can be obtained using the Horvitz-Thompson estimator [@horvitz1952generalization]. If $\tau$ is a population total, the Horvitz-Thompson estimate of $\tau$, denoted by $\hat{\tau}_{ht}$, is is given by
\begin{align}\label{eq:ht}
  \hat{\tau}_{ht} = \sum_{i = 1}^n Z_i \pi_i^{-1},
\end{align}
where $Z_i$ is the value of the $i$th population unit in the sample and $\pi_i$ is the inclusion probability of the $i$th population unit in the sample. An estimate of the population mean is obtained by dividing $\hat{\tau}_{ht}$ by $N$, the number of population units. 

It is also important to quantify uncertainty $\hat{\tau}_{ht}$.  @horvitz1952generalization and @sen1953estimate provide variance estimators for $\hat{\tau}_{ht}$, but these estimators have two drawbacks. First, they rely on calculating $\pi_{ij}$, the probability that population unit $i$ and population unit $j$ are both in the sample -- this quantity can be challenging if not impossible to calculate analytically. Second, these estimators ignore the spatial locations of the population units. To address these two drawbacks simultaneously, @stevens2003variance proposed the local neighborhood variance estimator. The local neighborhood variance estimator does not rely on $\pi_{ij}$ and incorporates spatial locations -- for technical details see @stevens2003variance. @stevens2003variance show the local neighborhood variance estimator tends to reduce the estimated variance of $\hat{\tau}$ and yield narrower confidence intervals compared to variance estimators that ignore spatial locations.

### Finite Population Block Kriging

Finite Population Block Kriging (FPBK) is a model-based approach that expands the geostatistical Kriging framework to the finite population setting [@verhoef2008spatial]. Instead of developing inference based on a specific sampling design, we assume the data are generated by a spatial stochastic process. We summarize some of the basic principles of FBPK next (for more technical details, see @verhoef2008spatial) Let ${\mathbf{z} \equiv \{\text{z}(s_1), \text{z}(s_2), . . . , \text{z}(s_N) \}}$ be an $N \times 1$ response vector at locations $s_1$, $s_2$, . . . , $s_N$ that can be measured at the $N$ population units. Suppose we want to use a sample to predict some linear function of the response variable, $f(\mathbf{z}) = \mathbf{b}^\prime \mathbf{z}$, where $\mathbf{b}^\prime$ is a $1 \times N$ vector of weights (e.g, the population mean is represented by a weights vector whose elements all equal one). Denoting quantities that are part of the sampled population units with a subscript \emph{s} and quantities that are part of the unsampled population units with subscript \emph{u}, let

\begin{equation}
\begin{pmatrix} \label{equation:Zmarginal}
    \mathbf{z}_s      \\
    \mathbf{z}_u
\end{pmatrix}
=
\begin{pmatrix}
  \mathbf{X}_s    \\
  \mathbf{X}_u
\end{pmatrix}
\bm{\beta} +
\begin{pmatrix}
\bm{\delta}_s    \\
\bm{\delta}_u
\end{pmatrix},
\end{equation}
where $\mathbf{X}_s$ and $\mathbf{X}_u$ are the design matrices for the sampled and unsampled population units, respectively, $\bm{\beta}$ is the parameter vector of fixed effects, and $\bm{\delta} \equiv [\bm{\delta}_s \,\, \bm{\delta}_u]'$, where $\bm{\delta}_s$ and $\bm{\delta}_u$ are random errors for the sampled and unsampled population units, respectively. 

FBPK assumes $\bm{\delta}$ in Equation$~$\ref{equation:Zmarginal} has mean-zero and a spatial correlation structure that can be modeled using a covariance function. This covariance function is commonly assumed to be non-negative (between zero and one), second-order stationary (depending only on the distance between population units), isotropic (independent of direction), and decay with distance between population units [@cressie1993statistics]. Henceforth, it is implied that we have made these same assumptions regarding $\bm{\delta}$, though @chiles1999geostatistics, pp. 80-93 discuss covariance functions that are not second-order stationary, not isotropic, or both. A variety of flexible covariance functions can be used to model $\bm{\delta}$ [@cressie1993statistics]; one example is the exponential covariance function (for a thorough list of spatial covariance functions, see @cressie1993statistics. The $i,j$th element of the exponential covariance matrix, $\cov(\bm{\delta})$, is
\mbox{}
\begin{align}\label{equation:expcov}
\cov(\delta_i, \delta_j) = 
\begin{cases} 
\sigma^2_{1}\exp(-h_{i,j}/\phi) & h_{i,j} > 0 \\
\sigma^2_{1} + \sigma^2_2 & h_{i,j} = 0
\end{cases}
,
\end{align}
where $\sigma^2_{1}$ is the variance parameter quantifying the variability that is dependent (coarse-scale), $\sigma^2_{2}$ is the variance parameter quantifying the variability that is independent (fine-scale), $\phi$ is the range parameter measuring the distance-decay rate of the covariance, and $h_{i,j}$ is the Euclidean distance between population units $i$ and $j$. The proportion of variability attributable to dependent random error is $\sigma^2_{1} / (\sigma^2_{1} + \sigma^2_{2})$. Similarly, the proportion of variability attributable to independent random error is $\sigma^2_{2} / (\sigma^2_{1} + \sigma^2_{2})$. Finally we note that $\sigma^2_{1}$ and $\sigma^2_{2}$ are often called the partial sill and nugget, respectively. 

With the above model formulation, the Best Linear Unbiased Predictor (BLUP) for $f(\mathbf{b}'\mathbf{z})$ and its prediction variance can be computed. While details of the derivation are in @verhoef2008spatial, we note here that the predictor and its variance are both moment-based, meaning that they do not rely on any distributional assumptions.

Other approaches, such as k-nearest-neighbors [@fix1989discriminatory; @ver2013comparison], random forests [@breiman2001random], Bayesian models [@chan2020bayesian], among others, could also be used to obtain predictions for a mean or total from spatially correlated responses of a finite population. Compared to the k-nearest-neighbors and random forest approach, we prefer FBPK because it is model-based and relies on theoretically-based variance estimators leveraging the model's spatial covariance structure, whereas k-nearest-neighbors and random forests use ad-hoc variance estimators [@ver2013comparison]. Additionally, @ver2013comparison studied compared FBPK, k-nearest-neighbors, and random forests in a variety of spatial data contexts, and FBPK tended to perform best. Compared to the Bayesian approach, we prefer FPBK mostly because it is much more computationally efficient.

# Materials and Methods {#sec:mm}

## Simulation Study {#sec:mm_sim}

We used a simulation study to investigate performance of four sampling-analysis combinations: IRS with a design-based analysis, called "IRS-Design"; IRS with a model-based analysis, called "IRS-Model"; GRTS sampling with a design-based analysis, called "GRTS-Design"; GRTS sampling with a model-based analysis, called "GRTS-Model". These combinations are also provided in Table \ref{tab:designanalysis}.

```{r, echo = FALSE, results = "asis"}
tab <- matrix(c("IRS-Design", "IRS-Model", "GRTS-Design", "GRTS-Model"),
       nrow = 2, byrow = TRUE) %>%
  as.table()
row.names(tab) <- c("IRS", "GRTS")
xtab1 <- xtable(tab, col.names = c("Design", "Model"), caption = "\\label{tab:designanalysis} Sampling-analysis combinations in the simulation study. The rows give the two types of sampling designs and the columns give the two types of analyses.")
align(xtab1) <- "r|ll"
names(xtab1) <- c("Design", "Model")
print(xtab1, comment = FALSE)
## I really want "Analysis" to appear as a row header and "Sampling Design" 
## to appear as a column header, but this isn't easy to figure out.
## I couldn't figure this out with xtable either so it might need to be
## made "by hand."
```

Performance for the four sampling-analysis combinations was evaluated in 36 different simulation scenarios. The 36 scenarios resulted from the crossing of three sample sizes, two location layouts, two response types, and three proportions of dependent random error. The three sample sizes ($n$) were $n = 50, n = 100,$ and $n = 200$. Samples were always selected from a population size ($N$) of $N = 900$. The two location layouts (of the population units) were random and gridded. Locations in the random layout were randomly generated inside the unit square ($[0, 1] \times [0, 1]$). Locations in the gridded layout were placed on a fixed, equally spaced grid inside the unit square. The two response types were normal and lognormal. For the normal response type, the response was simulated using mean-zero random errors with the exponential covariance (Equation$~$\ref{equation:expcov}) for varying proportions of dependent random error. The proportion of dependent random error is represented by $\sigma^2_1 / (\sigma^2_1 + \sigma^2_2)$, where $\sigma^2_1$ and $\sigma^2_2$ are the dependent random error variance (partial sill) and independent random error variance (nugget), respectively, from Equation$~$\ref{equation:expcov}. The total variance, $\sigma^2_1 + \sigma^2_2$, was always 2. The range was always $\sqrt{2} / 3$, which means that the correlation in the dependent random error decayed to nearly zero at the largest possible distance between two units in the domain. For the lognormal response type, the response was first simulated using the same approach as for the normal response type, except that the total variance was 0.6931 instead of 2. The response was then exponentiated, yielding a random variable whose total variance is 2. The lognormal responses were used to evaluate performance of the sampling-analysis approaches for data that were skewed (i.e., not normal).

```{r, echo = FALSE, results = "asis"}
n <- c("50", "100", "200")
site_locations <- c("Random", "Gridded", "")
psill_ratio <- c("0", "0.5", "0.9")
resp_type <- c("Normal", "Lognormal", "")
parm_tab <- rbind(n, site_locations, psill_ratio, resp_type)
parm_tab[c(2, 4), 3] <- "-"
row.names(parm_tab) <- c("Sample Size (n)", "Location Layout", 
                         "Proportion of Dependent Error", "Response Type")
# parm_tab <- parm_tab[c(1, 2, 4, 3), ]
parm_xtab <- xtable(parm_tab, caption = "\\label{tab:parmtab} Simulation scenario options. All combinations of sample size, location layout, response type, and proportion of dependent random error composed the 36 simulation scenarios. In each simualtion scenario, the total variance was two.")
align(parm_xtab) <- "r|lll"
print(parm_xtab, include.colnames = FALSE, hline.after = c(0, nrow(parm_xtab)), comment = FALSE)
```

In each of the 36 simulation scenarios, there were 2000 independent simulation trials. In each trial, IRS and GRTS samples were selected and then design-based and model-based analyses were used to estimate (design-based) or predict (model-based) the mean and construct confidence (design-based) or prediction (model-based) intervals. Then we recorded the bias, squared error, and interval coverage for all sampling-analysis combinations. After all 2000 trials, we summarized the long-run performance of the combinations by calculating average bias, rMS(P)E (root-mean-squared error for the design-based approaches and root-mean-squared-prediction error for the model-based approaches), and the proportion of times the true mean is contained in its 95% interval. The GRTS algorithm and the local neighborhood variance estimator are available in the \textbf{\textsf{R}} package `spsurvey` [@dumelle2021spsurvey]. FPBK is available in the `sptotal` \textbf{\textsf{R}} package [@higham2021sptotal] and covariance parameters were estimated using Restricted Maximum Likelihood  [@patterson1971recovery; @harville1977maximum; @wolfinger1994computing].

## Application {#sec:mm_app}

The Environmental Protection Agency (EPA), states, and tribes periodically conduct National Aquatic Research Surveys (NARS) in the United States to assess the water quality of various bodies of water. We will use data from the 2012 National Lakes Assessment (NLA), which measures various aspects of lake health and water quality for lakes in the contiguous United States [@USEPA2012NLA]. Specifically, we will analyze mercury concentration in lakes. Although we know the true mean mercury concentration values for the 986 lakes from the 2012 NLA, we will explore whether or not we obtain an adequately precise estimate for the realized mean mercury concentration if we sample only 100 of the 986 lakes. For each of the four familiar sampling-analysis combinations (IRS-Design, IRS-Model, GRTS-Design, and GRTS-Model), we estimate

# Results {#sec:results}

## Simulation Study {#sec:r_sim}

The average bias was nearly zero for all four combinations in all 36 scenarios, so we omit a more detailed summary of those results here. Tables for average bias in all 36 simulation scenarios are provided in the supporting information.

Fig. \ref{fig:figeff} shows the relative rMS(P)E of the four approaches from Table \ref{tab:designanalysis} using the random location layout with "IRS-Design" as the baseline.
<!--- figure 2 -->
\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/rmspe_eff.jpeg}
  \caption{Relative rMS(P)E for the four sampling-analysis combinations. The rows indicate the proportion of dependent error and the columns indicate the response type.}
  \label{fig:figeff}
\end{figure}
The relative rMS(P)E is defined as
\begin{equation*}
\frac{\text{rMS(P)E of sampling-analysis combination}}{\text{rMS(P)E of IRS-Design}},
\end{equation*}
When there is no spatial correlation (Fig. \ref{fig:figeff}, "Prop DE: 0" row), the four sampling-analysis combinations have approximately equal rMS(P)E. So using the GRTS sampling plan or a model-based analysis does not result in much, if any, loss in efficiency compared to IRS-Design when there is no spatial correlation. When there is spatial correlation (Fig. \ref{fig:figeff}, "Prop DE: 0.5" and "Prop DE: 0.9" rows), GRTS-Model tends to perform best, followed by GRTS-Design, IRS-Model, and finally IRS-Design, though the difference in relative rMS(P)E among GRTS-Model, GRTS-Design, and IRS-Model is relatively small.  As the strength of spatial correlation increases, the gap in rMS(P)E between IRS-Design and the other sampling-analysis combinations widens. Finally we note that when there is spatial correlation, IRS-Model outperforms IRS-Design by a large margin, suggesting that the poor design properties of IRS are largely mitigated by the model-based analysis. These conclusions are similar to those observed in the grid location layout, so we omit a grid location layout figure here. Tables for rMS(P)E in all 36 simulation scenarios are provided in the supporting information.

We also studied 95% interval coverage among the sampling-analysis combinations. The design-based confidence intervals and model-based prediction intervals were constructed using the normal distribution. Justification for this comes from the asymptotic normality of means via the Central Limit Theorem.  

Fig. \ref{fig:figconf} shows the 95% interval coverage for each of the four sampling-analysis combinations in the random location layout.
<!--- figure 3 -->
\begin{figure}
  \centering
  \includegraphics[width = 1\linewidth]{figures/coverage.jpeg}
  \caption{Interval coverage for the four sampling-analysis combinations. The rows indicate the proportion of dependent error and the columns indicate the response type. The solid, black line in each plot represents 95\% coverage.}
  \label{fig:figconf}
\end{figure}
Within each scenario, the sampling-analysis combinations tend to have fairly similar interval coverage. Coverage in the normal response scenarios was usually near 95%, while coverage in the lognormal response scenarios varied from from 90% to 95%. Coverage tended to always increase with the sample size. At a sample size of 200, all four sampling-analysis combinations had approximately 95% interval coverage in both response scenarios for all dependent error proportions.  These conclusions are similar to those observed in the grid location layout, so we omit a grid location layout figure here. Tables for interval coverage in all 36 simulation scenarios are provided in the supporting information.

## Application {#sec:r_app}

Fig. \ref{fig:merc} shows that mercury concentration is right-skewed, with most lakes having a low value of mercury concentration but a few having a much higher concentration. Mercury concentration exhibits some spatial patterning, with high mercury concentrations in lakes in the northeast and north central United States. Fig. \ref{fig:merc} also shows the spatial dependence in mercury concentration via the empirical semivariogram. The empirical semivariogram can be used as a tool to visualize spatial dependence. It quantifes the halved squared differences (semivariance) among mercury concentration at different distances apart. When a process is spatially correlated, the semivariance tends to be smaller at small distances and larger at large distances. Together, the map, histogram, and semivariogram in Fig. \ref{fig:merc} suggest that mercury concentration is skewed and exhibits spatial dependence. Lastly we note that the realized mean mercury concentration in the 986 lakes is 103.2 ng / g.
\begin{figure}
\centering
\begin{subfigure}{0.98\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/mercury_map.jpeg}
  \caption*{}
  \label{fig:mercury_map}
\end{subfigure} \\
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/mercury_hist.jpeg}
  \caption*{}
  \label{fig:mercury_hist}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
  \centering
  \includegraphics[width = 1\linewidth]{figures/sv_plot.jpeg}
  \caption*{}
  \label{fig:sv_plot}
\end{subfigure}
\caption{Mercury concentration visualizations for the population (Hg) for 986 lakes in the contiguous United States. A spatial layout is in the top row, a histogram is in the bottom row and left column, and an empirical semivariogram is in the bottom row and right column.}
\label{fig:merc}
\end{figure}

We selected a single IRS sample and a single GRTS sample and estimated (design-based) or predicted (model-based) the mean mercury concentration and its standard error using using design-based and model-based approaches. For the model-based analyses, the exponential covariance was used. Table \ref{tab:appliedtab} shows the results from these analyses. For all four sampling-analysis combinations, the true realized mean mercury concentration is within the bounds of the 95% confidence (design-based) or prediction (model-based) intervals. Though we should not generalize these results to other samples from these data, we do note a couple of patterns. The design-based IRS analysis shows the largest standard error: a likely reason is that this is the only approach that does not incorporate any spatial information regarding mercury concentration. Both analyses using GRTS sampling have lower standard errors than both analyses using IRS sampling. We expect that these patterns are consistent with other samples from these data because mercury concentration exhibits spatial patterning, so a spatially balanced sample should usually yield a lower standard error. 

```{r apptab, results = "asis"}
res_df <- readr::read_csv(here("inst", "output", "application", "application.csv"))
res_df_drop <- res_df[ ,-2]
names(res_df_drop) <- c("Approach", "Estimate", "SE", "95% LB", "95% UB")
xtab_app <- xtable(res_df_drop, digits = 1, caption = "\\label{tab:appliedtab} Application of design-based and model-based approaches to the NLA data set on mercury concentration. The true mean concentration is 103.2 ng / g.")
print(xtab_app, include.rownames = FALSE, comment = FALSE)
```

# Discussion {#sec:discussion}

The design-based and model-based approaches to statistical inference are fundamentally different paradigms by which samples are selected and data are analyzed. The design-based approach incorporates randomness through sampling to estimate population parameters. The model-based approach incorporates randomness through distributional assumptions to predict realized values of a random process. Though these approaches have often been compared in the literature both from theoretical and analytical perspectives, our contribution lies in studying them in a spatial context while implementing spatially balanced sampling. Aside from the theoretical differences described, a few analytical findings from the simulation study are particularly notable. First, the sampling decision (GRTS vs IRS) is most important when using a design-based analysis. Though GRTS-Model still outperformed IRS-Model, the model-based analysis mitigated much of the inefficiency of the IRS sample. Second, independent of the analysis approach, we found no reason to prefer IRS over GRTS for sampling spatial data -- GRTS-Design and GRTS-Model generally performed at least as well as their IRS counterparts when there was no spatial correlation and noticeably better than their IRS counterparts when there was spatial correlation. Third, as the strength of spatial correlation increases, the gap in rMS(P)E between IRS-Design and the other sampling-analysis combinations also increases. Fourth and finally, when the response was normal, interval coverage for all sampling-analysis combinations was very close to 95% for all sample sizes; when the response was lognormal, interval coverage for all sampling and analysis was between 90% and 95% and closest to 95% when $n = 200$.

There are several benefits and drawbacks of the design-based and model-based approaches for finite population spatial data. Some we have discuss, but others we have not and they are worthy of consideration in future research.  Design-based approaches are often computationally efficient, while model-based estimation can be computationally burdensome, especially for likelihood-based methods such as REML that rely on inverting a covariance matrix. The design-based approach also more naturally handles binary data, free from the more complicated logistic regression framework commonly used to analyze binary data in a model-based approach. The model-based approach, however, can more naturally quantify the relationship between covariates (predictor variables) and response variable. The model-based approach also yields estimated spatial covariance parameters, which help better understand the dependence structure in the process of study. Model selection is also possible using model-based approaches and criteria such as cross validation, likelihood ratio tests, or AIC [@akaike1974new]. Model-based approaches are capable of more efficient small-area estimation than design-based approaches by leveraging distributional assumptions in areas with few observed sites. Model-based approaches can also compute site-by-site predictions at unobserved locations and use them to construct informative visualizations. The benefits and drawbacks of both approaches, alongside our theoretical and analytical comparisons, can motive the process of choosing among them. This is especially true from an analysis perspective, as we found that using a spatially balanced sampling algorithm benefits both design-based and model-based analyses.

# Acknowledgments {.unnumbered}

The views expressed in this manuscript are those of the authors and do not necessarily represent the views or policies of the U.S. Environmental Protection Agency or the National Oceanic and Atmospheric Administration. Any mention of trade names, products, or services does not imply an endorsement by the U.S. government, the U.S. Environmental Protection Agency, or the National Oceanic and Atmospheric Administration. The U.S. Environmental Protection Agency and National Oceanic and Atmospheric Administration do not endorse any commercial products, services, or enterprises.

# Conflict of Interest Statement {.unnumbered}

There are no conflicts of interest for any of the authors.

# Data and Code Availability {.unnumbered}

This manuscript has a supplementary R package that contains all of the data and code used in its creation. The supplementary R package is hosted on GitHub. Instructions for download at available at

[https://github.com/michaeldumelle/DvMsp](https://github.com/michaeldumelle/DvMsp).

# Supporting Information {.unnumbered}

In the supporting information, we provide tables presenting summary statistics for all 36 simulation scenarios.

# Author Contributions {.unnumbered}

All authors conceived the ideas; All authors designed methodology; MD and MH performed the simulations and analyzed the data; MD and MH led the writing of the manuscript; All authors contributed critically to the drafts and gave final approval for publication. 

# References {#references .unnumbered}

