---
title: A comparison of design-based and model-based approaches for spatial data.
author:
  - name: In alphabetical order Michael Dumelle
    email: Dumelle.Michael@epa.gov
    affiliation: USEPA
    footnote: 1
  - name: Matt Higham
    email: mhigham@stlaw.edu
    affiliation: STLAW
    footnote: 1
  - name: Lisa Madsen
    affiliation: OSU
  - name: Anthony R. Olsen
    affiliation: USEPA
  - name: Jay M. Ver Hoef
    affiliation: NOAA
address:
  - code: USEPA
    address: United States Environmental Protection Agency, 200 SW 35th St, Corvallis, Oregon, 97333
  - code: STLAW
    address: Saint Lawrence University Department of Math, Computer Science, and Statistics, 23 Romoda Drive, Canton, New York, 13617
  - code: OSU
    address: Oregon State University Department of Statistics, 239 Weniger Hall, Corvallis, Oregon, 97331
  - code: NOAA
    address: Marine Mammal Laboratory, Alaska Fisheries Science Center, National Oceanic and Atmospheric Administration, Seattle, Washington, 98115
footnote:
  - code: 1
    text: "Corresponding Author"
abstract: |
  This is the abstract.

journal: "An awesome journal"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
linenumbers: true
numbersections: true
csl: elsevier-harvard.csl
preamble: >
  \usepackage{bm}
  \usepackage{bbm}
  \usepackage{color}
  \DeclareMathOperator{\var}{{var}}
  \DeclareMathOperator{\cov}{{cov}}
output: rticles::elsevier_article
---

_Text based on elsarticle sample manuscript, see [http://www.elsevier.com/author-schemas/latex-instructions#elsarticle](http://www.elsevier.com/author-schemas/latex-instructions#elsarticle)_

Potential Journals:

* Ecological Applications
* Methods in Ecology and Evolution
* Journal of Applied Ecology
* Environmetrics
* Environmental and Ecological Statistics

<!-- Notes from today -->
<!-- •	Finite populations require a smaller scope but we need to discuss the impact of infinite populations as well – put finite vs infinite population context in the introduction / similarities and differences -->
<!-- •	What should a lower sample size be? 50 seems reasonable 30 may be too small – maybe 50, 100, 200 -->
<!-- •	IRS results seem off for dependent error sample size 50 -->
<!-- •	Take home points – don’t have to do GRTS design with GRTS sample -->
<!-- •	Take home points – GRTS is better for both model and design, while spatial approach for design is close to spatial model -->
<!-- •	Add medium dependence -->
<!-- •	Remind readers what choices of the four approaches in the application mean – what do they mean to practitioners -->

# Introduction {#sec:introduction}

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  warning = FALSE, 
  message = FALSE,
  include = TRUE, 
  echo = FALSE
)
library(tidyverse)
library(here)
library(xtable) # latex tables
```

<!-- Brief introduction to model based and design based -->

There are two general approaches for using data to make statistical inferences about a population: design-based approaches and model-based approaches. When data cannot be obtained for all units in a population (population units), data on a subset of the population units is collected in a  sample. In the design-based approach, inferences about the underlying population are informed from a probabilistic process in which population units are selected to be in the sample. Alternatively, in the model-based approach, inferences are made from specific assumptions about the underlying process that generated the data. Each paradigm has a deep historical context [@sterba2009alternative] and its own set of general advantages [@hansen1983evaluation].

<!-- Shift focus to spatial data -->

__Tony O.__: Should this paragraph address that spatial information can be incorporated in the design stage or in the analysis stage (or both). In general, it's not clear whether we are referring to site selection process or the estimation process

Though the design-based and model-based approaches apply to statistical inference in a broad sense, we focus on comparing these approaches for spatial data. We define spatial data as data that incorporates the specific locations of the population units into either the design or estimation process. @de1990model give an early comparison of design-based and model-based approaches for spatial data, quashing the belief that design-based approaches could not be used for spatially correlated data. Thereafter, several comparisons between design-based and model-based for spatial data have been considered, but they tend to compare design-based approaches that ignore spatial locations to model-based approaches [@brus1997random; @verhoef2002sampling; @verhoef2008spatial]. @cooper2006sampling review the two approaches in an ecological context before introducing a "model-assisted" variance estimator that combines aspects from each approach. In addition to @cooper2006sampling, there has been substantial research and development into estimators that use both design and model-based principles (see e.g. @cicchitelli2012model, @chan2020bayesian for a Bayesian approach, and @sterba2009alternative). More recent overviews include @brus2020statistical and @wang2012review, but no numerical comparison has been made between design-based approaches that incorporate spatial locations and model-based approaches.

<!-- Outline for the rest of the paper -->

__Lisa M.__: Add paragraph describing contribution of manuscript.

The rest of this paper is organized as follows. In Section \ref{sec:background}, we compare sampling and estimation procedures between the design-based approach and the model-based approach. In Section \ref{sec:numstudy}, we use simulated and real data to study the the behavior of both approaches. And in Section \ref{sec:discussion}, we end with a discussion and provide directions for future research. 

# Background {#sec:background}

The design-based and model-based approaches incorporate randomness in fundamentally different ways. In this section, we describe the role of randomness and its effects on subsequent inferences. We then discuss specific inference methods for the design-based and model-based approaches for spatial data. 

## Comparing Design-Based vs. Model-Based

The design-based approach assumes the population is fixed. Randomness is incorporated in the selection of population units according to a sampling design. A sampling design assigns a positive probability of inclusion in the sample (inclusion probability) to each population unit. Some examples of commonly used sampling designs include simple random sampling, stratified random sample, and cluster
sampling, which we refer to as Independent Random Sampling (IRS) survey designs. The goal is to use the sampling design and the sampled data to estimate population parameters like means and totals. These population parameters are traditionally assumed to be fixed but unknown. 

Treating the data as fixed and incorporating randomness through the sampling design yields estimators having very few other assumptions. Confidence intervals for these types of estimators are typically derived using limiting arguments. Means and totals, for example, are asymptotically normally distributed by the Central Limit Theorem. @sarndal2003model and @lohr2009sampling provide thorough reviews of the design-based approach.

__Jay VH__: I think it is important to stress that the limiting distribution is over all possible randomizations, constrained by whatever design is used.

__Jay VH__: quantity is vague. We should stick with variables, or realized variables (we might also call these values, but we should define and establish a consistent terminology early on.) __Matt H__: I think, though this comment is for this paragraph, we should establish the terminology earlier.

The model-based approach assumes the data are a random realization of a data-generating process. Randomness is often incorporated through distributional assumptions on this process. Instead of estimating fixed but unknown parameters (as in the design-based approach), the goal of model-based inference in the spatial context is often \emph{prediction} of an unknown quantity. For example, suppose the realized mean of all population units is the quantity of interest. Instead of \emph{estimating} a fixed unknown mean, we are \emph{predicting} the value of the mean, a random variable. We know that if we sampled all population units, we would have an exact prediction for the mean of our one realized process, without any uncertainty. But we are often not interested in the true, unknown mean of the underlying process.

Assuming the data is a realization of a specific data-generating process yields predictors that are linked to distributional assumptions. These distributional assumptions are used to derive prediction intervals. The distributional assumptions allow the prediction intervals to be more precise. @cressie1993statistics and @schabenberger2017statistical provide reviews of model-based approaches for spatial data.

<!-- Figure 1a. Brus (2020): Data is fixed. In a finite population example, show a 3d surface that can be generated by anything. If we repeatedly sample the surface, then 95% of all 95% CIs will contain the true mean, which never changes. -->

```{r fig1, out.width = "100%", fig.cap = "A comparison of sampling under the design-based and model-based frameworks. Points circled are those that are sampled. In the top row, we have one fixed population, and two random samples. In the bottom row, we have two realizations of the same spatial process sampled at the same locations."}
set.seed(08032021)

source(here("R", "sim_pop.R"))
N <- 25
pop_df <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                  psill = 0.9, erange = 1, nugget = 0.1)

n <- 5
samp_df <- pop_df %>% sample_n(n) 
samp_df2 <- pop_df %>% sample_n(n) 

library(cowplot)
d1 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df, size = 5.5, shape = 1, 
             show.legend = FALSE, stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Design 1")

d2 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df2, size = 5.5, shape = 1, show.legend = FALSE,
             stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Design 2")


pop_df_mod <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                      psill = 0.9, erange = 1, nugget = 0.1)
pop_df_mod2 <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                       psill = 0.9, erange = 1, nugget = 0.1)
indeces <- sample(1:N, size = n, replace = FALSE)
samp_df_mod <- pop_df_mod %>% slice(indeces)
samp_df_mod2 <- pop_df_mod2 %>% slice(indeces)

m1 <- ggplot(data = pop_df_mod, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Model 1")

m2 <- ggplot(data = pop_df_mod2, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod2, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Model 2")

library(gridExtra)
grid.arrange(d1, d2, m1, m2)
```

Description of Figure \ref{fig:fig1} goes here.

<!-- Figure 1b. Spatial process is fixed. In a finite population example, show 10 3d surfaces that are generated from some model. If we repeatedly generate the surface and obtain a sample, then 95% of all 95% PIs will contain the realized means. The realized mean changes from surface to surface and it's not necessarily the case that 95% of all 95% PIs will contain the true, underlying mean. -->

__Tony O.__: Before this section is it useful to have a section that lays out the general site selection and general analysis options. Thinking about site selection as design-based IRS, design-based GRTS, Arbitrary set of sites, selection for model-based. Then general analysis options as design-based no spatial, design-based spatial, model-based. This four by three table would show that model-based analyses are possible for all selection options. Design-based options with no spatial info possible for IRS-based and GRTS-based. Design-based options with spatial info possible for GRTS-based.

__Jay VH__: What about the design for model-based inference? Strictly speaking, it is fixed – there is no probabilistic use of a randomized design. However, we are going to have to deal with Diggle et al. (2010).

## Spatially Balanced Design and Analysis

__Lisa M.__: Need a more precise definition of "miniature" in this context, and need an example.

__Jay VH__: Saying "the distribution of the sampled population units mirrors the density of..." is confusing to me. Are these formal statistical definitions of distribution (cumulative distribution function) and density (probability density function)? Wouldn’t IRS sample be a miniature, as it should, on average, mirror a population?

The design-based approach can use spatial locations to obtain spatially balanced samples. First we discuss spatial balance with respect to the population [@stevens2004spatially]. A sample is spatially balanced with respect to the population if the sampled population units are a miniature of the population units. A sample is a miniature of the population if the distribution of the sampled population units mirrors the density of all population units. Spatial balance with respect to the population is different than spatial balance with respect to geography. A sample that is spatially balanced with respect to geography is spread out in some type of equidistant manner over geographical space and is not meant to be miniatures of the population. When we refer to spatial balance henceforth, we mean spatial balance with respect to the population. 

Spatially balanced samples are useful because they tend to yield estimates that have lower variance than estimates constructed from sampling designs lacking spatial balance [@stevens2004spatially; @barabesi2011sampling; @grafstrom2013well; @robertson2013bas; @wang2013design; @benedetti2017spatiallyreview]. To quantify spatial balance, @stevens2004spatially proposed loss functions based on Voroni polygons. The first spatially balanced sampling algorithm that saw widespread use was the Generalized Random Tessellation Stratified [@stevens2004spatially]. Since GRTS was developed, several other spatially balanced sampling algorithms have emerged, including the Local Pivotal Method [@grafstrom2012spatially; @grafstrom2018spatially], Spatially Correlated Poisson Sampling [@grafstrom2012spatiallypoisson], Balanced Acceptance Sampling [@robertson2013bas], Within-Sample-Distance [@benedetti2017spatially], and Halton Iterative Partitioning [@robertson2018halton]. We focus on the Generalized Random Tessellation Stratified (GRTS) algorithm to select spatially balanced sampling because it has several attractive properties, including __Lisa M.__: List major attractive properties, and detailed by @stevens2004spatially and @dumelle2021spsurvey.

<!-- algorithms. -->

The GRTS algorithm is used to sample from finite and infinite populations and works by utilizing a mapping between two-dimensional and one-dimensional space. The population units in two-dimensional space are divided into cells using a hierarchical index. Population units are then mapped to a one-dimensional line via the hierarchical indexing. The line length of each population unit equals its inclusion probability. A systematic sample is conducted on the line and these samples are linked to a population unit in two-dimensional space, which results in the desired sample. @stevens2004spatially and @dumelle2021spsurvey provide further details. 

<!-- This makes it seem like HT is being used to estimate population parameters in GRTS? Needs to be in there, but maybe a sentence making it clear that this isn't being used? Or just change the order and talk about Local variance first and then mention these for more general settings? -->

After collecting a sample using the GRTS algorithm, the data are used to estimate population parameters. The Horvitz-Thompson estimator [@horvitz1952generalization] yields unbiased estimates of population means and totals. For example, if $\tau$ is a population total, then the Horvitz-Thompson estimator of $\tau$ (denoted by $\hat{\tau}_{ht}$), is given by
\begin{align}\label{eq:ht}
  \hat{\tau}_{ht} = \sum_{i = 1}^n Z_i \pi_i^{-1},
\end{align}
where $Z_i$ and $\pi_i$ are the observed value and inclusion probability of the $i$th population unit selected in the sample. A similar formula exists for estimating the mean, $\mu$. @horvitz1952generalization and @sen1953estimate provide variance estimators for $\hat{\tau}_{ht}$, but they have two drawbacks. First, they rely on calculating $\pi_{ij}$, the probability that population unit $i$ and population unit $j$ are included in the sample, and this can be very difficult to calculate. Second, they ignore the spatial locations of the population units. To address these drawbacks, @stevens2003variance proposed a local neighborhood variance estimator. The local neighborhood variance estimator does not rely on $\pi_{ij}$, and it incorporates spatial locations by assigning higher weights to nearby observations. @stevens2003variance show this variance estimators tends to reduce the estimated standard error of $\hat{\tau}$, yielding narrower confidence confidence intervals for $\tau$.

## Finite Population Block Kriging

Finite Population Block Kriging (FPBK) is a model-based approach that expands the geostatistical Kriging framework to the finite population setting [@verhoef2008spatial]. Instead of basing inference off of a specific sampling design, we assume the data are generated by a spatial process. @verhoef2008spatial gives details on the theory of FPBK, but some of the basic principles are summarized below. Let $\mathbf{z} \equiv \{\text{z}(s_1), \text{z}(s_2), . . . , \text{z}(s_N) \}$ be a response vector at locations $s_1$, $s_2$, . . . , $s_N$ that can be measured at the $N$ population units and is represented as an $N \times 1$ vector. Suppose we want to predict some linear function of the response variable, $f(\mathbf{z}) = \mathbf{b}^\prime \mathbf{z}$, where $\mathbf{b}^\prime$ is a $1 \times N$ vector of weights. For example, if we want to predict the population total across all population units, then we would use a vector of 1's for the weights. 

<!-- how explicitly do we want to define \mathbf{z} -->

<!-- finite number of -->

<!-- confusing having two tau's: tau for total and a tau as a function -->

However, we often only have a sample of the $N$ population units. Denoting quantities that are part of the sampled population units with a subscript \emph{s} and quantities that are part of the unsampled population units with a subscript \emph{u}, 

\begin{equation}
\begin{pmatrix} \label{equation:Zmarginal}
    \mathbf{z}_s      \\
    \mathbf{z}_u
\end{pmatrix}
=
\begin{pmatrix}
  \mathbf{X}_s    \\
  \mathbf{X}_u
\end{pmatrix}
\bm{\beta} +
\begin{pmatrix}
\bm{\delta}_s    \\
\bm{\delta}_u
\end{pmatrix},
\end{equation}
where $\mathbf{X}_s$ and $\mathbf{X}_u$ are the design matrices for the sampled and unsampled population units, respectively; $\beta$ is the parameter vector of fixed effects; and $\bm{\delta}_s$ and $\bm{\delta}_u$ are random errors for the sampled and unsampled population units, respectively. Denoting $\bm{\delta} \equiv [\bm{\delta}_s \,\, \bm{\delta}_u]'$, we assume the expectation of $\bm{\delta}$ equals $\mathbf{0}$.

We also assume that there is spatial correlation in $\bm{\delta}$, which can be modeled using a covariance function. It is common to assume the covariance function is second-order stationary and isotropic [@cressie1993statistics], and that the spatial covariance decreases as the separation between population units increases. Many spatial covariance functions exist, but the primary function we use throughout the simulations and applications in this manuscript is the exponential covariance function: the $i,j^{th}$ entry for $\cov(\bm{\delta})$ is
\mbox{}
\begin{align}\label{equation:expcov}
\cov(\delta_i, \delta_j) = \theta_1\exp(-3h_{i,j}/\theta_2) + \theta_3\mathbbm{1}\{\mathbf{h}_{i,j} = 0\}, 
\end{align}
where $h_{i,j}$ is the distance between population units $i$ and $j$, and $\bm{\theta}$ is a vector of spatial covariance parameters of the partial sill $\theta_1$, the range $\theta_2$, and the nugget $\theta_3$; and, $\mathbbm{1}$ is equal to 1 when distance $h_i,j$ is equal to 0, and equal to 0 otherwise. However, any spatial covariance function could be used in the place of the exponential, including functions that allow for non-stationarity or anisotropy [@chiles1999geostatistics, pp. 80-93].

__Lisa M.__ : Include formulas. Perhaps, but, these are very heavy in notation and matrix algebra. We might consider, however, adding the formulas to an Appendix.

With the above model formulation, the Best Linear Unbiased Predictor (BLUP) for $f(\mathbf{b}'\mathbf{z})$ and its prediction variance can be computed. While details of the derivation are in [@verhoef2008spatial], we note here that the predictor and its variance are both moment-based.

We note that we only use FPBK in this paper in order to focus more on comparing the design-based and model-based approaches. However, k-nearest-neighbors [@fix1951discriminatory; @ver2013comparison], random forest [@breiman2001random], Bayesian models [@chan2020bayesian], among others, can also be used to obtain predictions for a mean or total from spatially correlated responses in a finite population setting. We choose to use FPBK because it is faster than a Bayesian approach and random forest and because @ver2013comparison showed that the method outperforms k-nearest-neighbors in many scenarios. 

# Numerical Study {#sec:numstudy}

There were several variables to alter in the simulations, and the names of the scenarios in future plots mirror these variables

* correlation type: dependent errors or independent errors
* error type:
    * normal: mean 0, variance 2
    * lognormal: log scale mean 0, log scale variance 2 (total variance 47)
    * lognormalbig: log scale mean 0, log scale variance 4 (total variance 2,926)
* sample sizes: $n = 10, 50, 150; N = 900$
* layout: gridded vs random uniform population locations confined to a 1 x 1 unit square

So for example, the `inderror.normal.n50.randloc` is the simulation having independent random errors that are normal, a sample size of 50, and random population locations. 

There were 2000 trials for each simulation. The original response (before exponentiating if applicable) for the dependent error cases was normally distributed with an exponential covariance function with partial sill of 0.9, effective range of $\sqrt{2}$, and a nugget of 0.1. For the independent error cases, the partial sill was 0 and the nugget was 1.

__Lisa M.__ Notes: adding an intermediate level of spatial dependency?
Transfer simulation scenarios to a table
Explain what the effective range is
Fill in the details of what exactly each approach means (perhaps a table would be a good way to do this)
Reorder the sims in the first figure by some criterion.
Think about what would be a "reasonable sample size" instead of 10.
Define medae
If the data has a large right-skew, wouldn't one consider a transformation before the analysis? We should address this by stating that the BLUP for the log response does not mean that e^logBLUP is the BLUP for the response on the original scale.


In each simulated data set, a GRTS sample and an IRS sample were selected. Then for the GRTS sample, the design-based approach using the local neighborhood variance (Design GRTS) and a model-based approach were applied (Model GRTS). Then for the IRS sample, the design-based approach using the simple random sample variance (Design IRS) and a model-based approach were applied (Model IRS).


```{r, results = "asis", eval = FALSE}
sim_one <- read_csv(here("inst", "output", "sim_one", "summ_output.csv"))
colnames(sim_one) <- c("Approach", "Bias", "RMSE", "MedAE", "Coverage", "PClose", "MedIL")
sim_one_table <- xtable(sim_one, digits = 4, caption = "Approach, mean bias (Bias), root-mean-squared error (RMSE), median absolute error (MedAE), 95 percent interval coverage (Coverage), proportion of times the approach was closer to the true value (PClose), and median interval length (MedIL)", type = "latex", latex.environments = "center", label = "tab:sim_one")
print(sim_one_table, include.rownames = FALSE, comment = FALSE)
```

The GRTS algorithm and the local neighborhood variance estimator are available in the \textbf{\textsf{R}} package \texttt{spsurvey} [@dumelle2021spsurvey]. FPBK can be readily performed in `R` with the `sptotal` package [@higham2020sptotal]. We use `sptotal` for both the simulation analysis and the application, estimating parameters with Restricted Maximum Likelihood (REML).

MAJOR POINTS for the following Figure, which has relative efficiency (rmspe / Design IRS rmspe): We see that

- When there is no spatial correlation (top row), we aren't losing that much by using a spatial method over Design IRS, even if assumptions are violated.
- When there is a lot of spatial correlation Model GRTS tends to perform best, but difference in relative efficiency between Model GRTS and Design GRTS is not very big. In many settings Design GRTS outperforms Model IRS by a large margin, suggesting that the design decision (whether to use IRS or GRTS) is much more important than the analysis decision (whether to analyze using model assumptions or not). 
- If there is a large amount of spatial correlation, we should __not__ use IRS. Even though it's assumptions are satisfied, the resulting estimator is much worse than an estimator using a spatially balanced sample.
- If we are comparing design-based and model-based methods, we should not use a poor design to compare with (give examples?).


```{r, results = "hide", message = FALSE, warning = FALSE}
library(tidyverse)
library(here)

files <- list.files(path = here("inst", "output", "sims914"), pattern = "*.csv", full.names = TRUE)

combo_data <- purrr::map_df(files,
                            ~read_csv(.x) %>% mutate(filename = .x))

combo_data <- combo_data %>%
  dplyr::filter(n != 10 & gridded == FALSE) %>%
  mutate(sim = interaction(n, psill, resptype)) %>% ## , gridded
  mutate(approach = fct_relevel(approach, c("Design IRS", "Model IRS",
                                            "Design GRTS", "Model GRTS"))) %>%
  mutate(resptype = fct_relevel(resptype, c("normal", "lognormal")))
combo_data <- combo_data %>% group_by(sim) %>% mutate(designirsrmspe = if_else(approach == "Design IRS", true = rmspe, false = NA_real_)) %>%
  fill(designirsrmspe, .direction = "downup") %>%
  mutate(rel_efficiency = rmspe / designirsrmspe) %>%
  ungroup()

ggplot(data = combo_data, aes(x = n, y = rel_efficiency, colour = approach)) +
  facet_grid(psill ~ resptype) +
  geom_jitter(width = 7) +
  scale_colour_manual(values = c("goldenrod1", "goldenrod4", "mediumpurple1", "mediumpurple4"))
```


MAJOR POINTS for the following Figure:

- when we drop the IRS samples to compare the GRTS samples more closely (looking at the relative efficiency of model rmspe / design rmspe), we see that the model-based approach is usually better than the design-based approach (but, keep in mind that the improvement was small compared to the improvement of both methods over Design IRS).
- when the model used is the same model that generated the data, the Model-based approach far outperforms the Design-based approach, especially when there is a lot of spatial correlation (bottom-left facet). The methods perform similarly when there is no spatial correlation.
- even when the model that generates the data is different than the model used to fit the data (lognormal), the model-based approach still outperforms the design-based approach when there is a high amount of spatial correlation.

```{r}
combo_data_grts <- combo_data %>%
  dplyr::filter(approach %in% c("Design GRTS", "Model GRTS")) %>%
  mutate(designgrts = if_else(approach == "Design GRTS", 
                              true = rmspe,
                              false = NA_real_)) %>%
  group_by(sim) %>%
  fill(designgrts, .direction = "updown") %>%
  ungroup() %>%
  mutate(releffgrts = rmspe / designgrts)
combo_data_grts_model <- combo_data_grts %>%
  filter(approach == "Model GRTS")

ggplot(data = combo_data_grts_model, aes(x = n, y = rel_efficiency)) +
  facet_grid(psill ~ resptype) +
  geom_point()
```

MAJOR POINTS for the following Figure:

- coverage for the model-based estimator is slightly higher than coverage for the design-based estimator in the normal settings. Coverages are about equal in the lognormal settings with a slight edge to model-based (this is the point that will be tougher to explain: I would have expected the design-based estimator to have better coverage in the lognormal settings because it has fewer assumptions).
- coverage is at or near the nominal 95% in all of the normal settings, where assumptions for the model approach and the design approach are satisfied.
- for the model-based approach, the more skewed the population is, the higher the sample size needed to satisfy CLT for predicting a mean. The derivation of the BLUP is entirely moment-based (no distribution assumed) but we still need to assume a distribution to estimate spatial parameters and to generate bounds of a prediction interval.
- many confidence intervals generated for design-based approaches also rely on the CLT and the normal distribution to generate the interval. Again, for highly skewed data with a small sample size, this assumption is violated even though all of the assumptions for generating the estimator are valid.

```{r}
ggplot(data = combo_data_grts, aes(x = n, y = coverage, colour = approach)) +
  geom_hline(yintercept = 0.95) +
  geom_jitter(width = 7) + 
  facet_grid(psill ~ resptype) +
  scale_colour_manual(values = c("mediumpurple1", "mediumpurple4"))
```

Major Points from August 3 Simulations:

1. In most of the dependent error simulation settings, either all four approahces (IRS-Design, IRS-Model, GRTS-Design, and GRTS-Model) perform equally or GRTS-Design and GRTS-Model outperform IRS-Design and IRS-Model. Exceptions to this are a couple of the settings with very small sample sizes (n = 10), in which the IRS does better than GRTS. In the independent error settings, it usually doesn't matter much which approach is used, which makes sense.


2. We will now focus on comparing Design-GRTS to Model-GRTS, the two best approaches for any reasonable sample size. In the independent error settings, the two approaches perform very similarly, so those results are omitted in the following graph. In the dependent error settings, using rmspe as the performance criterion, Model-GRTS outperforms Design-GRTS in 12 of the 18 settings, the two approaches perform very similarly in 3 settings, and Design-GRTS outperforms Model-GRTS in 3 settings.

3. Focusing in on the three settings where Design-GRTS outperforms Model-GRTS, we see that, in two of the settings, the log-normal response has a large variance, corresponding to a large right-skew after exponentiation. All three settings have sites in random locations. However, in only one of these settings would we recommend actually using Design-GRTS. In the other two settings, the data are sufficiently skewed that a practitioner should not use either approach, though it is "safer" to use Design-GRTS.

4. Coverage 

For Gaussian errors, coverage for all approaches tended to be near 0.95. There was less between-approach deviation in coverages for random locations compared to grid locations. Generally, the larger the skew, the worse the coverage,and the larger the sample size, the better the coverage. Design GRTS (local neighborhood variance) tended to slightly undercover, a result Tony was familiar with.

```{r}
## View(combo_data %>% filter(approach == "Design IRS"))
ggplot(data = combo_data, aes(x = sim, y = coverage, colour = approach)) +
  geom_hline(yintercept = 0.95) +
  geom_point() +
  coord_flip()
```



5. Take-home messages

- In terms of rmspe, a model-based analysis on a GRTS design yields an rmspe similar to or lower than a design-based analysis on a GRTS design, as long as the response variable is not "too skewed." 
- If the response variable is very skewed, then neither analysis is appropriate, but, the design-based analysis is better. 
- a spatially balanced GRTS sample outperforms IRS in nearly all dependent error settings, as expected.
- methods that use spatial correlation generally perform better on random location points than they do on gridded points. This makes some intuitive sense because (1) on average, the minimum distance between an unobserved point and its nearest observed neighbor should be lower for random points and (2) the span of the study area is maximized for a grid based on the way that we set up the simulations (with the random points being drawn as uniform random variables within the boundary of the grid). 
- comparison of Design-GRTS and Model-GRTS between two settings with different locations of points, but otherwise the same simulation parameters, should really be done on the same surface realization. One very strange realized response vector could drastically alter the results, especially on the exponentiated log data. In the same way that we compare the four approaches on the same realized data, we should also try to do the same with the locations, if they are of interest. (The realized mean won't be exactly the same but should be close).

# Application

The Environmental Protection Agency (EPA), states, and tribes periodically conduct National Aquatic Research Surveys (NARS) in the United States to assess the water quality of various bodies of water. We will use the 2012 National Lakes Assessment (NLA), which measures various aspects of lake health and quality in lakes in the contiguous United States, to obtain an interval for mean mercury concentration. Although all lakes in the survey were measured in 2012, there may not always be enough time or money to do so. Therefore, we will explore whether or not we can still obtain an adequately precise estimate for the realized mean mercury concentration if we only take a sample of 100 of the 986 lakes.

```{r, message = FALSE, warning = FALSE, echo = FALSE, results = "hide"}
library(tidyverse)
library(here)
library(SpatialDesignVModel)
data(nla)
nla_df
factor(nla_df$TOTALHG_UNITS) ## all same units

nla_df %>% group_by(SITE_ID) %>%
  summarise(nonmiss = sum(!is.na(TOTALHG_RESULT))) %>%
  ungroup() %>% summarise(maxnonmiss = max(nonmiss))
## HG never measured twice at the same site.

nla_df %>% group_by(SITE_ID) %>%
  summarise(nonmiss = sum(!is.na(TOTALHG_RESULT))) %>%
  summarise(sumnomiss = sum(nonmiss == 0))
## 35 sites never have HG measured. These will be dropped as well as the duplicate sites.

## in duplicate sites, fill in the value for RDis_IX
nla_nomiss <- nla_df %>%
  group_by(SITE_ID) %>%
  fill(RDis_IX, .direction = "downup") %>%
  ungroup() %>%
  filter(!is.na(TOTALHG_RESULT)) %>%
  rename(total_hg = "TOTALHG_RESULT")

nla_nomiss_both <- nla_nomiss
## check
nla_nomiss_both %>% group_by(SITE_ID) %>% count() %>%
  ungroup() %>%
  summarise(not1 = sum(n != 1))

## transform coordinates
library(sptotal)
coord_list <- LLtoTM(cm = mean(nla_nomiss_both$INDEX_LON_DD),
                     lat = nla_nomiss_both$INDEX_LAT_DD, 
                     lon = nla_nomiss_both$INDEX_LON_DD)
nla_nomiss_both$xcoords <- coord_list$xy[ ,1]
nla_nomiss_both$ycoords <- coord_list$xy[ ,2]
```

```{r figdata, out.width = "100%", fig.cap = "Population distribution of mercury concentration for 986 lakes in the contiguous United States. Thirty-five lakes were dropped from the analysis because they were missing mercury concentration.", message = FALSE, warning = FALSE}
merc <- ggplot(data = nla_nomiss_both, aes(x = total_hg)) +
  geom_histogram(colour = "black", fill = "white", bins = 15) +
  labs(x = "HG (ng / g)")
# dist <- ggplot(data = nla_nomiss_both, aes(x = RDis_IX)) +
#   geom_histogram(colour = "black", fill = "white", bins = 15) +
#   labs(x = "Lakeshore Disturbance")
merc_map <- ggplot(data = nla_nomiss_both, aes(x = xcoords, y = ycoords)) +
  geom_point(aes(colour = total_hg)) +
  scale_colour_viridis_c() +
  labs(x = "", y = "", colour = "hg") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  coord_quickmap() 
# dist_map <- ggplot(data = nla_nomiss_both, aes(x = xcoords, y = ycoords)) +
#   geom_point(aes(colour = RDis_IX)) +
#   scale_colour_viridis_c() +
#   labs(x = "", y = "", colour = "Dist") +
#   theme(axis.text.x = element_blank(),
#         axis.text.y = element_blank(),
#         axis.ticks = element_blank())
library(gridExtra)
# grid.arrange(merc, merc_map, nrow = 2)
merc_map
```

```{r, echo = FALSE, results = "hide"}
mean(nla_nomiss_both$total_hg)
# mean(nla_nomiss_both$RDis_IX)
```

Figure \ref{fig:figdata} shows that mercury concentration is right-skewed, with most lakes having a low value of mercury concentration but a few having a much higher concentration. Mercury concentration exhibits some spatial correlation, with high mercury concentrations in lakes in the northeast and north central United States. Because we are considering these lakes to be our entire population, we know that the realized mean mercury concentration is 103.2 ng / g.

```{r, results = "hide", fig.keep = "none"}
## IRS Sample, Model Analysis

set.seed(080421)
n <- 100
lakesobs <- nla_nomiss_both %>% sample_n(n) 
lakesunobs <- anti_join(nla_nomiss_both, lakesobs)
lakesunobs$total_hg <- NA

lakes_test <- bind_rows(lakesobs, lakesunobs) 
lakes_test$wts <- 1 / nrow(lakes_test) ## predicting for mean

slmfitout_exp_lakes <- slmfit(formula = total_hg ~ 1,
                              data = lakes_test, 
                              xcoordcol = 'xcoords',
                              ycoordcol = 'ycoords',
                              CorModel = "Exponential")
summary(slmfitout_exp_lakes)
plot(slmfitout_exp_lakes)

pred_exp_lakes <- predict(slmfitout_exp_lakes, wtscol = "wts",
                          conf_level = 0.95)
print(pred_exp_lakes)
mean_irs_mod <- pred_exp_lakes$FPBK_Prediction
se_irs_mod <- sqrt(pred_exp_lakes$PredVar)
lb_irs_mod <- pred_exp_lakes$conf_bounds[1]
ub_irs_mod <- pred_exp_lakes$conf_bounds[2]

realized_mean <- mean(nla_nomiss_both$total_hg) ## compute realized mean
```

```{r, results = "hide"}
## IRS Sample, Design Analysis
## 
irs_info <- lakesobs %>% summarise(meandoc = mean(total_hg),
                                   vardoc = var(total_hg))
N <- nrow(nla_nomiss_both); n <- nrow(lakesobs)
irs_se_irs_samp <- sqrt((irs_info$vardoc / n) * (N - n) / N)
irs_lb_irs_samp <- irs_info$meandoc - 1.96 * irs_se_irs_samp
irs_ub_irs_samp <- irs_info$meandoc + 1.96 * irs_se_irs_samp
irs_info$meandoc; sqrt(irs_info$vardoc)
irs_lb_irs_samp; irs_ub_irs_samp
```

```{r, results = "hide"}
## GRTS Sample, Design Analysis
data_sf <- sf::st_as_sf(nla_nomiss_both, coords = c("xcoords", "ycoords"),
                        crs = 5070)
library(spsurvey)
grts_samp <- grts(data_sf, n_base = n)
grts_bind <- sprbind(grts_samp)

## get coordinates
grts_coords <- sf::st_coordinates(grts_bind)
## make data frame
grts_df <- data.frame(
  response = grts_bind$total_hg,
  x = grts_coords[, "X"],
  y = grts_coords[, "Y"],
  siteID = grts_bind$siteID,
  wgt = grts_bind$wgt
)
## head(grts_df)
summary(grts_df$response)

design_analysis <- cont_analysis(
  grts_df,
  siteID = "siteID",
  vars = "response",
  weight = "wgt",
  xcoord = "x",
  ycoord = "y"
)
## just return the mean info
## design_mean <- subset(design_analysis$Pct, Statistic == "Mean")
design_mean_grts <- design_analysis$Mean
design_mean_grts$Estimate
design_mean_grts$StdError
design_mean_grts$LCB95Pct
design_mean_grts$UCB95Pct
```

```{r, results = "hide"}
## GRTS Sample, Model Analysis

grts_coords_resp <- grts_df %>% select(-siteID, -wgt) %>%
  rename(total_hg = "response", xcoords = "x", ycoords = "y")
grts_unsamp <- anti_join(nla_nomiss_both, grts_coords_resp)
grts_unsamp$total_hg <- NA
grts_unsamp <- grts_unsamp %>% select(total_hg, xcoords, ycoords)
grts_full <- dplyr::bind_rows(grts_coords_resp, grts_unsamp)

grts_full$wts <- 1 / nrow(grts_full)
mod_grts <- slmfit(total_hg ~ 1, data = grts_full,
                   xcoordcol = "xcoords",
                   ycoordcol = "ycoords")
pred_mod_grts <- predict(mod_grts, wtscol = "wts")
model_mean_grts <- pred_mod_grts$FPBK_Prediction
model_se_grts <- sqrt(pred_mod_grts$PredVar)
model_lb_grts <- model_mean_grts + -1 * 1.96 * model_se_grts
model_ub_grts <- model_mean_grts + 1 * 1.96 * model_se_grts
model_mean_grts
model_se_grts
model_lb_grts
model_ub_grts
```

```{r, results = "hide"}
## combine results
res_df <- tibble(approach = c("Design IRS", "Design GRTS", "Model IRS", "Model GRTS"),
       realized_mean = c(realized_mean, realized_mean, realized_mean,
                     realized_mean),
       estimate = c(irs_info$meandoc,
                    design_mean_grts$Estimate, as.vector(mean_irs_mod),
                    as.vector(model_mean_grts)),
       se = c(irs_se_irs_samp, design_mean_grts$StdError, as.vector(se_irs_mod),
              as.vector(model_se_grts)),
       lb = c(irs_lb_irs_samp, design_mean_grts$LCB95Pct, as.vector(lb_irs_mod),
              as.vector(model_lb_grts)),
       ub = c(irs_ub_irs_samp, design_mean_grts$UCB95Pct, as.vector(ub_irs_mod),
              as.vector(model_ub_grts)))
res_df <- res_df %>% slice(1, 3, 2, 4)
```

```{r apptab}
library(knitr)
res_df_drop <- res_df[ ,-2]
names(res_df_drop) <- c("Approach", "Estimate", "SE", "95% LB", "95% UB")
kable(res_df_drop, digits = 1, caption = "\\label{tab:appliedtab} Application of design-based and model-based approaches to the NLA data set on mercury concentration. The true mean concentration is 103.2 103.2 ng / g")
```

Table \ref{tab:appliedtab} shows the application of a design-based analysis on an IRS, a model-based analysis on an IRS, a design-based analysis on a GRTS sample, and a model-based analysis on a GRTS sample. We see that, for all four analyses, the true realized mean mercury concentration is within the bounds of the 95% intervals. However, we should not generalize the results of this particular realization to any other data set or even to other potential samples of this data set. 

But, we do note a couple of patterns. The design-based IRS analysis shows the largest standard error: a likely reason is that this is the only approach that does not use the spatial correlation in mercury concentration across the contiguous United States. We also see that, for the samples drawn, the both analyses with the GRTS sampling design have a lower standard error than the analyses with the IRS sampling design. We would expect this to be the case for most samples because mercury concentration exhibits spatial correlation so a spatially balanced sample should usually yield a lower standard error. If it is acceptable to have an interval for mean mercury concentration of about 25 ng / g and if we ignore the other variables that the EPA collects information on in these NLA surveys, then the EPA could consider sampling just 50 lakes to save time and money. 

# Discussion {#sec:discussion}

* Pros of Design-Based (items we are not exploring): computationally efficient, few assumptions, more naturally handles binary data, 

* Pros of Model-Based (items we are not exploring): covariate inference, more efficient small-area estimation, model selection?, estimated spatial parameters to better understand spatial structure, site-by-site predictions/prediction map

# References {#references .unnumbered}

