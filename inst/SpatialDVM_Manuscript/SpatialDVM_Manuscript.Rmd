---
title: A comparison of design-based and model-based approaches for spatial data.
author:
  - name: In alphabetical order Michael Dumelle
    email: Dumelle.Michael@epa.gov
    affiliation: USEPA
    footnote: 1
  - name: Matt Higham
    email: mhigham@stlaw.edu
    affiliation: STLAW
    footnote: 1
  - name: Lisa Madsen
    affiliation: OSU
  - name: Anthony R. Olsen
    affiliation: USEPA
  - name: Jay M. Ver Hoef
    affiliation: NOAA
address:
  - code: USEPA
    address: United States Environmental Protection Agency, 200 SW 35th St, Corvallis, Oregon, 97333
  - code: STLAW
    address: Saint Lawrence University Department of Math, Computer Science, and Statistics, 23 Romoda Drive, Canton, New York, 13617
  - code: OSU
    address: Oregon State University Department of Statistics, 239 Weniger Hall, Corvallis, Oregon, 97331
  - code: NOAA
    address: Marine Mammal Laboratory, Alaska Fisheries Science Center, National Oceanic and Atmospheric Administration, Seattle, Washington, 98115
footnote:
  - code: 1
    text: "Corresponding Author"
abstract: |
  This is the abstract.

journal: "An awesome journal"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
linenumbers: true
numbersections: true
csl: elsevier-harvard.csl
preamble: >
  \usepackage{bm}
  \usepackage{bbm}
  \usepackage{color}
  \DeclareMathOperator{\var}{{var}}
  \DeclareMathOperator{\cov}{{cov}}
output: rticles::elsevier_article
---

_Text based on elsarticle sample manuscript, see [http://www.elsevier.com/author-schemas/latex-instructions#elsarticle](http://www.elsevier.com/author-schemas/latex-instructions#elsarticle)_

Potential Journals:

* Ecological Applications
* Methods in Ecology and Evolution
* Journal of Applied Ecology
* Environmetrics
* Environmental and Ecological Statistics

# Introduction {#sec:introduction}

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  warning = FALSE, 
  message = FALSE,
  include = TRUE, 
  echo = FALSE
)
library(tidyverse)
library(here)
library(xtable) # latex tables
```

<!-- Brief introduction to model based and design based -->

There are two general approaches for using data to make statistical inferences about a population: design-based approaches and model-based approaches. When data cannot be obtained for all units in a population (population units), data on a subset of the population units is collected in a  sample. In the design-based approach, inferences about the underlying population are informed from a probabilistic process in which population units are selected to be in the sample. Alternatively, in the model-based approach, inferences are made from specific assumptions about the underlying process that generated the data. Each paradigm has a deep historical context [@sterba2009alternative] and its own set of general advantages [@hansen1983evaluation].

<!-- Shift focus to spatial data -->

Though the design-based and model-based approaches apply to statistical inference in a broad sense, we focus on comparing these approaches for spatial data. We define spatial data as variables measured at specific geographic locations. @de1990model give an early comparison of design-based and model-based approaches for spatial data, quashing the belief that design-based approaches could not be used for spatially correlated data. Thereafter, several comparisons between design-based and model-based for spatial data have been considered, but they tend to compare design-based approaches that ignore spatial locations to model-based approaches [@brus1997random; @verhoef2002sampling; @verhoef2008spatial]. @cooper2006sampling review the two approaches in an ecological context before introducing a "model-assisted" variance estimator that combines aspects from each approach. In addition to @cooper2006sampling, there has been substantial research and development into estimators that use both design and model-based principles (see e.g. @cicchitelli2012model, @chan2020bayesian for a Bayesian approach, and @sterba2009alternative). More recent overviews include @brus2020statistical and @wang2012review, but no numerical comparison has been made between design-based approaches that incorporate spatial locations and model-based approaches.

<!-- Outline for the rest of the paper -->

The rest of this paper is organized as follows. In Section \ref{sec:background}, we compare sampling and estimation procedures between the design-based approach and the model-based approach. In Section \ref{sec:numstudy}, we use simulated and real data to study the the behavior of both approaches. And in Section \ref{sec:discussion}, we end with a discussion and provide directions for future research. 

# Background {#sec:background}

The design-based and model-based approaches incorporate randomness in fundamentally different ways. In this section, we describe the role of randomness and its effects on subsequent inferences. We then discuss specific inference methods for the design-based and model-based approaches for spatial data. 

## Comparing Design-Based vs. Model-Based

The design-based approach assumes the data are fixed. Randomness is incorporated in the selection of population units according to a sampling design. A sampling design assigns a positive probability of inclusion in the sample (inclusion probability) to each population unit. Some examples of commonly used sampling designs include independent random sampling (IRS), stratified random sampling, and cluster sampling. The goal is to use the sampling design and the sampled data to estimate population parameters like means and totals. These population parameters are typically assumed to be fixed but unknown. 

Treating the data as fixed and incorporating randomness through the sampling design yields estimators having very few other assumptions. Confidence intervals for these types of estimators are typically derived using limiting arguments. Means and totals, for example, are asymptotically normally distributed by the Central Limit Theorem. @sarndal2003model and @lohr2009sampling provide thorough reviews of the design-based approach.

The model-based approach assumes the data are a random realization of a data-generating process. Randomness is often incorporated through distributional assumptions on this process. Instead of estimating fixed but unknown parameters (as in the design-based approach), the goal of model-based inference in the spatial context is often \emph{prediction} of an unknown quantity. For example, suppose the realized mean of all population units is the quantity of interest. Instead of \emph{estimating} a fixed unknown mean, we are \emph{predicting} the value of the mean, a random variable. We know that if we sampled all population units, we would have an exact prediction for the mean of our one realized process, without any uncertainty. But we are typically not interested in the true, unknown mean of the underlying process.

Assuming the data is a realization of a specific data-generating process yields predictors that are linked to distributional assumptions. These distributional assumptions are used to derive prediction intervals. The distributional assumptions allow the prediction intervals to be more precise. @cressie1993statistics and @schabenberger2017statistical provide reviews of model-based approaches for spatial data.

<!-- Figure 1a. Brus (2020): Data is fixed. In a finite population example, show a 3d surface that can be generated by anything. If we repeatedly sample the surface, then 95% of all 95% CIs will contain the true mean, which never changes. -->

```{r fig1, out.width = "100%", fig.cap = "A comparison of sampling under the design-based and model-based frameworks. In the top row, we have one fixed population, and two random samples. In the bottom row, we have two realizations of the same spatial process sampled at the same locations."}
set.seed(06092021)

source(here("R", "sim_pop.R"))
N <- 25
pop_df <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                  psill = 0.9, erange = 1, nugget = 0.1)

n <- 5
samp_df <- pop_df %>% sample_n(n) 
samp_df2 <- pop_df %>% sample_n(n) 

library(cowplot)
d1 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df, size = 5.5, shape = 1, 
             show.legend = FALSE, stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Design 1")

d2 <- ggplot(data = pop_df, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df2, size = 5.5, shape = 1, show.legend = FALSE,
             stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Design 2")


pop_df_mod <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                      psill = 0.9, erange = 1, nugget = 0.1)
pop_df_mod2 <- sim_pop(N = N, gridded = TRUE, cortype = "Exponential",
                       psill = 0.9, erange = 1, nugget = 0.1)
indeces <- sample(1:N, size = n, replace = FALSE)
samp_df_mod <- pop_df_mod %>% slice(indeces)
samp_df_mod2 <- pop_df_mod2 %>% slice(indeces)

m1 <- ggplot(data = pop_df_mod, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Model 1")

m2 <- ggplot(data = pop_df_mod2, aes(x = x, y = y)) +
  geom_point(aes(colour = response), size = 4) +
  scale_colour_viridis_c() +
  geom_point(data = samp_df_mod2, size = 5.5, shape = 1, show.legend = FALSE, stroke = 1.5) +
  theme_minimal_grid() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Model 2")

library(gridExtra)
grid.arrange(d1, d2, m1, m2)
```

Description of Figure \ref{fig:fig1} goes here.

<!-- Figure 1b. Spatial process is fixed. In a finite population example, show 10 3d surfaces that are generated from some model. If we repeatedly generate the surface and obtain a sample, then 95% of all 95% PIs will contain the realized means. The realized mean changes from surface to surface and it's not necessarily the case that 95% of all 95% PIs will contain the true, underlying mean. -->

## Spatially Balanced Design and Analysis

The design-based approach can use spatial locations to obtain spatially balanced samples. First we discuss spatial balance with respect to the population [@stevens2004spatially]. A sample is spatially balanced with respect to the population if the sampled population units are a miniature of the population units. A sample is a miniature of the population if the distribution of the sampled population units mirrors the density of all population units. Spatial balance with respect to the population is different than spatial balance with respect to geography. A sample that is spatially balanced with respect to geography is spread out in some type of equidistant manner over geographical space and is not meant to be miniatures of the population. When we refer to spatial balance henceforth, we mean spatial balance with respect to the population. 

Spatially balanced samples are useful because they tend to yield estimates that have lower variance than estimates constructed from sampling designs lacking spatial balance [@stevens2004spatially; @barabesi2011sampling; @grafstrom2013well; @robertson2013bas; @wang2013design; @benedetti2017spatiallyreview]. To quantify spatial balance, @stevens2004spatially proposed loss functions based on Voroni polygons. The first spatially balanced sampling algorithm that saw widespread use was the Generalized Random Tessellation Stratified [@stevens2004spatially]. Since GRTS was developed, several other spatially balanced sampling algorithms have emerged, including the Local Pivotal Method [@grafstrom2012spatially; @grafstrom2018spatially], Spatially Correlated Poisson Sampling [@grafstrom2012spatiallypoisson], Balanced Acceptance Sampling [@robertson2013bas], Within-Sample-Distance [@benedetti2017spatially], and Halton Iterative Partitioning [@robertson2018halton]. We focus on the Generalized Random Tessellation Stratified (GRTS) algorithm to select spatially balanced sampling because it has several attractive properties detailed by @stevens2004spatially and @dumelle2021spsurvey.

<!-- algorithms. -->

The GRTS algorithm is used to sample from finite and infinite populations and works by utilizing a mapping between two-dimensional and one-dimensional space. The population units in two-dimensional space are divided into cells using a hierarchical index. Population units are then mapped to a one-dimensional line via the hierarchical indexing. The line length of each population unit equals its inclusion probability. A systematic sample is conducted on the line and these samples are linked to a population unit in two-dimensional space, which results in the desired sample. @stevens2004spatially provide and @dumelle2021spsurvey provide further details. 

<!-- This makes it seem like HT is being used to estimate population parameters in GRTS? Needs to be in there, but maybe a sentence making it clear that this isn't being used? Or just change the order and talk about Local variance first and then mention these for more general settings? -->

After collecting a sample using the GRTS algorithm, the data are used to estimate population parameters. The Horvitz-Thompson estimator [@horvitz1952generalization] yields unbiased estimates of population means and totals. For example, if $\tau$ is a population total, then the Horvitz-Thompson estimator of $\tau$ (denoted by $\hat{\tau}_{ht}$), is given by
\begin{align}\label{eq:ht}
  \hat{\tau}_{ht} = \sum_{i = 1}^n Z_i \pi_i^{-1},
\end{align}
where $Z_i$ and $\pi_i$ are the observed value and inclusion probability of the $i$th population unit selected in the sample. A similar formula exists for estimating the mean, $\mu$. @horvitz1952generalization and @sen1953estimate provide variance estimators for $\hat{\tau}_{ht}$, but they have two drawbacks. First, they rely on calculating $\pi_{ij}$, the probability that population unit $i$ and population unit $j$ are included in the sample, and this can be very difficult to calculate. Second, they ignore the spatial locations of the population units. To address these drawbacks, @stevens2003variance proposed a local neighborhood variance estimator. The local neighborhood variance estimator does not rely on $\pi_{ij}$, and it incorporates spatial locations by assigning higher weights to nearby observations. @stevens2003variance show this variance estimators tends to reduce the estimated standard error of $\hat{\tau}$, yielding narrower confidence confidence intervals for $\tau$.

## Finite Population Block Kriging

Finite Population Block Kriging (FPBK) is a model-based approach that expands the geostatistical Kriging framework to the finite population setting [@verhoef2008spatial]. Instead of basing inference off of a specific sampling design, we assume the data are generated by a spatial process. @verhoef2008spatial gives details on the theory of FPBK, but some of the basic principles are summarized below. Let $\mathbf{z} \equiv \{\text{z}(s_1), \text{z}(s_2), . . . , \text{z}(s_N) \}$ be a response variable that can be measured at the $N$ population units and is represented as an $N \times 1$ vector. Suppose we want to predict some linear function of the response variable, $f(\mathbf{z}) = \mathbf{b}^\prime \mathbf{z}$, where $\mathbf{b}$ is a $1 \times N$ vector of weights. For example, if we want to predict the population total across all population units, then we would use a vector of 1's for the weights. 

<!-- how explicitly do we want to define \mathbf{z} -->

<!-- finite number of -->

<!-- confusing having two tau's: tau for total and a tau as a function -->

Typically, however, we only have a sample of the $N$ population units. Denoting quantities that are part of the sampled population units with a subscript \emph{s} and quantities that are part of the unsampled population units with a subscript \emph{u}, 

\begin{equation}
\begin{pmatrix} \label{equation:Zmarginal}
    \mathbf{z}_s      \\
    \mathbf{z}_u
\end{pmatrix}
=
\begin{pmatrix}
  \mathbf{X}_s    \\
  \mathbf{X}_u
\end{pmatrix}
\bm{\beta} +
\begin{pmatrix}
\bm{\delta}_s    \\
\bm{\delta}_u
\end{pmatrix},
\end{equation}
where $\mathbf{X}_s$ and $\mathbf{X}_u$ are the design matrices for the sampled and unsampled population units, respectively; $\beta$ is the parameter vector of fixed effects; and $\bm{\delta}_s$ and $\bm{\delta}_u$ are random errors for the sampled and unsampled population units, respectively. Denoting $\bm{\delta} \equiv [\bm{\delta}_s \,\, \bm{\delta}_u]'$, we assume the expectation of $\bm{\delta}$ equals $\mathbf{0}$.

We also typically assume that there is spatial correlation in $\bm{\delta}$, which can be modeled using a covariance function. It is common to assume the covariance function is second-order stationary and isotropic [@cressie1993statistics], and that the spatial covariance decreases as the separation between population units increases. Many spatial covariance functions exist, but the primary function we use throughout the simulations and applications in this manuscript is the exponential covariance function: the $i,j^{th}$ entry for $\cov(\bm{\delta})$ is
\mbox{}
\begin{align}\label{equation:expcov}
\cov(\delta_i, \delta_j) = \theta_1\exp(-3h_{i,j}/\theta_2) + \theta_3\mathbbm{1}\{\mathbf{h}_{i,j} = 0\}, 
\end{align}
where $h_{i,j}$ is the distance between population units $i$ and $j$, and $\bm{\theta}$ is a vector of spatial covariance parameters of the partial sill $\theta_1$, the range $\theta_2$, and the nugget $\theta_3$, and $\mathbbm{1}$ is an indicator function. However, any spatial covariance function could be used in the place of the exponential, including functions that allow for non-stationarity or anisotropy [@chiles1999geostatistics, pp. 80-93].

With the above model formulation, the Best Linear Unbiased Predictor (BLUP) for $f(\mathbf{b}'\mathbf{z})$ and its prediction variance can be computed. While details of the derivation are in [@verhoef2008spatial], we note here that the predictor and its variance are both moment-based.

We note that we only use FPBK in this paper in order to focus more on comparing the design-based and model-based approaches. However, k-nearest-neighbors [@fix1951discriminatory; @ver2013comparison], random forest [@breiman2001random], Bayesian models [@chan2020bayesian], among others, can also be used to obtain predictions for a mean or total from spatially correlated responses in a finite population setting.

# Numerical Study {#sec:numstudy}

__Sample Simulation__

For the following simulation results, we simulated 1040 different gridded populations, each of size 900 (on the unit square) with sample size 150. For the design-based approach, population units were selected via GRTS, the Horvitz-Thompson estimator was used,and the local mean variance was used. For the model-based approach (FPBK), population units were selected via Independent Random Sampling (IRS) and the appropriate prediction and prediction variance formulas were used. 

The response was normally distributed with an exponential covariance function with partial sill of 0.9, effective range of $\sqrt{2}$, and a nugget of 0.1. For model-based, we assumed the correct form of the covariance function (exponential), but estimated the spatial parameters with REML.

```{r, results = "asis"}
sim_one <- read_csv(here("inst", "output", "sim_one", "summ_output.csv"))
colnames(sim_one) <- c("Approach", "Bias", "RMSE", "MedAE", "Coverage", "PClose", "MedIL")
sim_one_table <- xtable(sim_one, digits = 4, caption = "Approach, mean bias (Bias), root-mean-squared error (RMSE), median absolute error (MedAE), 95 percent interval coverage (Coverage), proportion of times the approach was closer to the true value (PClose), and median interval length (MedIL)", type = "latex", latex.environments = "center", label = "tab:sim_one")
print(sim_one_table, include.rownames = FALSE, comment = FALSE)
```

__Base Simulations__

* both good: correctly specified model with high correlation (we did this in Table \ref{tab:sim_one})
* break model: highly non-normal errors with small sample size
* break design: small area estimation

__Simulation Discussion Questions__

* model-based: how should sample be drawn? should locations be fixed?
* change n or sampling fraction?

__Other Base Settings?__

* both good?: misspecified covariance model with high correlation
* break both? non-gaussian areas with smaller sample size

## Software

The GRTS algorithm and the local neighborhood variance estimator are available in the \textbf{\textsf{R}} package \texttt{spsurvey} [@dumelle2021spsurvey]. FPBK can be readily performed in `R` with the `sptotal` package [@higham2020sptotal]. We use `sptotal` for both the simulation analysis and the application, estimating parameters with Restricted Maximum Likelihood (REML).

## Applied Example

Potential Data Sets:

* National Lakes Assessment 
* Moose in Alaska
* Temperature Data from NOAA

# Discussion {#sec:discussion}

# References {#references .unnumbered}

