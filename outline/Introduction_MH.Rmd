---
title: "Introduction"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\begin{itemize}
  \item Design-Based Overview \citep{Sarndal2003model, Lohr2009sampling}
  \item Model-Based Overview \citep{Cressie2015statistics, Schabenberger2017statistical}
  \item Design-Based and Model-Based Comparisons \citep{Hansen1983evaluation, Brus1997random, VerHoef2002sampling, Cooper2006sampling, sterba2009alternative, Brus2020statistical, Chan2020bayesian}
  \item Spatially Balanced Design and Analysis \citep{StevensOlsen2003VarianceEstimation, StevensOlsen2004GRTS}
  \item Finite Population Block Kriging \citep{VerHoef2002sampling, VerHoef2008spatial, Higham2020adjusting}
\end{itemize}

References from Brus2020statistical

* de Gruijter, J. J., & ter Braak, C. J. F. (1990). Model-free estimation from spatial samples: A reappraisal of classical sampling theory. Mathematical Geology, 22, 407–415
    * contains info on why classical sampling works with spatially correlated data.
    
* Brus, D. J., & de Gruijter, J. J. (1997). Random sampling or
geostatistical modelling? Choosing between design-based and
model-based sampling strategies for soil (with discussion). Geoderma, 80, 1–59
    * more comparison between the two appraoches
    
* I stopped at 2.3 

Design-based inference uses characteristics of the sampling design to obtain relevant confidence intervals for any parameters of interest. Typically, there are few assumptions involved because intervals are derived using the sampling design itself. Data is simply "there": we do not assume that it has been generated through some abstract model. We know that if we sampled all sites, we would have an exact value for the true mean, without any uncertainty.

On the other hand, model-based inference imposes additional assumptions on the data with the promise of providing more precise estimates if the additional assumptions hold. Instead of estimating true but unknown parameters, the goal of model-based inference in the spatial context is typically _prediction_ of an unknown quantity. This is a fundamental philosophical difference between sampling-based and model-based approaches. Instead of _estimating_ an fixed unknown mean, we are _predicting_ the value of the mean, a random variable. We know that if we sampled all sites, we would have an exact prediction for the mean of our one realized spatial surface, without any uncertainty. But, the true mean of the spatial process that generated our realized data is still not known, and, in the prediction context, we typically do not really care much about what it is.

Figure 1a. Data is fixed. In a finite population example, show a 3d surface that can be generated by anything. If we repeatedly sample the surface, then 95% of all 95% CIs will contain the true mean, which never changes.

```{r}
library(plotly)
```

Figure 1b. Spatial process is fixed. In a finite population example, show 10 3d surfaces that are generated from some model. If we repeatedly generate the surface and conduct our sample, then 95% of all 95% PIs will contain the realized means. The mean changes from surface to surface and it's not necessarily the case that 95% of all 95% PIs will contain the true, underlying mean.

